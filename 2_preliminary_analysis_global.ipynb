{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 2 - preliminary analysis, constant lifetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Jupyter notebook contains parts of modeling behind the publication: \n",
    "> Krych, K. & Pettersen, JB. (2024). Long-term lifetime trends of large appliances since the introduction in Norwegian households. Journal of Industrial Ecology. \n",
    "\n",
    "Here, we perform the preliminary analysis, in which we vary all the model parameters to identify the critical ones, i.e., we perform a global uncertainty and sensitivity analysis.\n",
    "\n",
    "We assume that the lifetime scale parameter follows a *constant* function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and simulation setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats\n",
    "from scipy.optimize import least_squares\n",
    "import SALib.sample.sobol\n",
    "import SALib.analyze.sobol\n",
    "import time\n",
    "import math\n",
    "import seaborn as sns\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), os.pardir, 'ODYM/odym/modules')))\n",
    "import ODYM_Classes as msc # import the ODYM class file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TimeStart = 1940\n",
    "TimeEnd = 2022\n",
    "SampleSize = 2**5\n",
    "\n",
    "problem = {}\n",
    "param_values = {}\n",
    "variables = {}\n",
    "MyYears = list(range(TimeStart,TimeEnd+1))\n",
    "variables_for_UA = ['I', 'k', 'P', 'PpD', 'C', 'k-cab', 'lambda-cab', 'SoCE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all values below are relative changes in parameters (percentage changes)\n",
    "u_i = 0.05\n",
    "u_k = 0.1   \n",
    "u_p = 0.01     \n",
    "u_ppd = 0.01    \n",
    "u_lambda_cab = 0.2 \n",
    "u_k_cab = 0.2 \n",
    "u_soce = 0.2     \n",
    "u_c = 0.01    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import funct # most functions are imported from funct.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lt_par_to_scale(t, lt_par):\n",
    "    [C0] = lt_par\n",
    "    scale = np.ones_like(t)*C0\n",
    "    return scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_popd_from_stock(t, stock, dict_values):\n",
    "    dwellings = dict_values['P']/dict_values['PpD']\n",
    "    s = dict_values['C']\n",
    "    sf = np.zeros((len(t), len(t)))\n",
    "    for m in range(0, len(t)):  # cohort index\n",
    "        sf[m::,m] = scipy.stats.weibull_min.sf(np.arange(0,len(t)-m), c=dict_values['k-cab'], loc = 0, scale=dict_values['lambda-cab'])\n",
    "\n",
    "    # MFA calculations start (assuming sf[0] != 0 and no negative inflows)\n",
    "    i = np.zeros(len(t))\n",
    "    s_c = np.zeros((len(t), len(t)))\n",
    "    i[0] = s[0] / sf[0, 0]\n",
    "    s_c[:, 0] = i[0] * sf[:, 0]\n",
    "    for m in range(1, len(t)):\n",
    "        i[m] = (s[m] - s_c[m, :].sum()) / sf[m,m]\n",
    "        s_c[m::, m] = i[m] * sf[m::, m]\n",
    "    \n",
    "    o_c = np.zeros_like(s_c)\n",
    "    o_c[1::,:] = -1 * np.diff(s_c,n=1,axis=0)\n",
    "    o_c[np.diag_indices(len(t))] = i - np.diag(s_c) # allow for outflow in year 0 already\n",
    "\n",
    "    soce = dict_values['SoCE'] # share of cabins electrified\n",
    "    soce[soce >1] = 1\n",
    "    TimeStart = t[0]\n",
    "    soce[:1960-TimeStart] = 0 \n",
    "    soce[soce <0] = 0\n",
    "    el_cabins = np.einsum('tc,c->t',s_c,soce)\n",
    "    popd = stock/(dwellings+el_cabins)\n",
    "    return popd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_MFA(lt_par, dict_values):\n",
    "    t = dict_values['t']\n",
    "    scale = lt_par_to_scale(t, lt_par)\n",
    "    # create a 2D array with shape parameters\n",
    "    lt_shape = np.full((len(t),len(t)), dict_values['k'], dtype=float)\n",
    "    lt_shape = np.tril(lt_shape, 0)\n",
    "    # create a 2D array with scale parameters\n",
    "    lt_scale = np.repeat(np.reshape(scale,(len(scale),1)), repeats=len(scale), axis=1)\n",
    "    lt_scale = np.tril(lt_scale, 0)\n",
    "    lt = {'Type': 'Weibull', 'Shape': lt_shape,'Scale': lt_scale}\n",
    "    # __find_unique_lt__\n",
    "    params = {k:v for k,v in lt.items() if k!= 'Type'}\n",
    "    sets = np.concatenate([[p] for p in params.values()], axis=0) # stacks all the p parameters\n",
    "    sets = sets.reshape(len(params),-1) # reshapes from 3D form (p,t,t) into 2D form (p,t*t)\n",
    "    unique, inverse = np.unique(sets, return_inverse=True, axis=1)\n",
    "    inverse = inverse.reshape(len(t),len(t)) # reshapes from 1D form (t*t) into 2D form (t,t)\n",
    "    length = np.shape(unique)[1]\n",
    "    unique = {k:unique[p,:] for p,k in enumerate(params.keys())}\n",
    "    # __compute_hz__\n",
    "    hz_unique = np.zeros((len(t),length))\n",
    "    for i in range(length): # for each unique parameter set\n",
    "        if unique['Scale'][i] != 0:\n",
    "            sf = scipy.stats.weibull_min.sf(np.arange(len(t)), c=unique['Shape'][i], loc = 0, scale=unique['Scale'][i])\n",
    "            hz_unique[0,i] = 1-sf[0]\n",
    "            for m in range(len(t)-1): # for each age m\n",
    "                if sf[m] != 0:\n",
    "                    hz_unique[m+1,i] = (sf[m] - sf[m+1]) / sf[m]\n",
    "                else:\n",
    "                    hz_unique[m+1,i] = 1\n",
    "    hz = np.zeros((len(t), len(t)))\n",
    "    for cohort in range(len(t)): # for each cohort c\n",
    "        for time in range(cohort,len(t)): # for each year t \n",
    "            hz[time,cohort] = hz_unique[time-cohort,inverse[time,cohort]]\n",
    "    # compute_inflow_driven_model\n",
    "    i = dict_values['I']\n",
    "    s_c = np.zeros((len(t), len(t))) # stock composition per year\n",
    "    o_c = np.zeros((len(t), len(t))) # outflow compositionO\n",
    "    for time in range(len(t)): # for each year t\n",
    "        if time>0: # the initial stock is assumed to be 0\n",
    "            o_c[time,:time] = s_c[time-1,:time] * hz[time,:time] \n",
    "            # subtract outflows of cohorts <m from the previous stock \n",
    "            s_c[time,:time] = s_c[time-1,:time] - o_c[time,:time]\n",
    "        # Add new cohort to stock\n",
    "        s_c[time,time] = i[time]\n",
    "        o_c[time,time] = s_c[time,time] * hz[time,time]\n",
    "    # popd calculation\n",
    "    popd = calculate_popd_from_stock(t, s_c.sum(axis=1), dict_values)\n",
    "    return popd, i, o_c, s_c, hz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_MFA_results(Dyn_MFA_System, dict_values, d, r, lt_fit):\n",
    "    popd, i, o_c, s_c, hz = perform_MFA(lt_fit, dict_values)\n",
    "    Dyn_MFA_System.FlowDict['F_01'].Values[:,d,r,0] = i\n",
    "    Dyn_MFA_System.FlowDict['F_10c'].Values[:,:,d,r,0] = o_c\n",
    "    Dyn_MFA_System.ExtraDict['F_10'].Values[:,d,r] = np.sum(o_c, axis=1)\n",
    "    Dyn_MFA_System.StockDict['S_1c'].Values[:,:,d,r,0] = s_c\n",
    "    Dyn_MFA_System.ExtraDict['S_1'].Values[:,d,r] = np.sum(s_c, axis=1)\n",
    "    Dyn_MFA_System.ExtraDict['POpD'].Values[:,d,r]= popd\n",
    "    Dyn_MFA_System.ExtraDict['hz'].Values[:,:,d,r]= hz\n",
    "    Dyn_MFA_System.ExtraDict['LT-l'].Values[:,d,r] = lt_fit[0]\n",
    "    return Dyn_MFA_System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def errfunc_var(lt_par, xdata, ydata, dict_values_r):\n",
    "    popd, i, o_c, s_c, hz = perform_MFA(lt_par, dict_values_r)\n",
    "    return popd[xdata-TimeStart]-ydata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ModelClassification_app  = {} # Create dictionary of model classifications\n",
    "\n",
    "ModelClassification_app['Time'] = msc.Classification(Name = 'Time', Dimension = 'Time', ID = 1, \n",
    "                                                 Items = MyYears)\n",
    "ModelClassification_app['Cohort'] = msc.Classification(Name = 'Cohort', Dimension = 'Time', ID = 2, \n",
    "                                                 Items = MyYears)\n",
    "ModelClassification_app['Element'] = msc.Classification(Name= 'Elements', Dimension = 'Element', ID = 3, \n",
    "                                                    Items = ['C'])\n",
    "ModelClassification_app['Durable'] = msc.Classification(Name = 'Durable', Dimension = 'Durable', ID = 4, \n",
    "                                                    Items = ['fridges' ,'freezers','washing machines', 'tumble dryers', 'dishwashers', 'ovens'])\n",
    "ModelClassification_app['Run'] = msc.Classification(Name = 'Model run', Dimension = 'Run', ID = 5, \n",
    "                                                    Items = [])\n",
    "aspects = ['Time','Element','Cohort', 'Durable', 'Run']\n",
    "letters = ['t','e', 'c','d', 'r']\n",
    "IndexTable = pd.DataFrame({'Aspect'        : aspects, # 'Time' and 'Element' must be present!\n",
    "                           'Description'   : ['Model aspect ' + asp for asp in aspects],\n",
    "                           'Dimension'     : [asp if asp != 'Cohort' else 'Time' for asp in aspects], # 'Time' and 'Element' are also dimensions\n",
    "                           'Classification': [ModelClassification_app[Aspect] for Aspect in aspects],\n",
    "                           'IndexLetter'   : letters}) # Unique one letter (upper or lower case) indices to be used later for calculations.\n",
    "IndexTable.set_index('Aspect', inplace = True) \n",
    "IndexTable['IndexSize'] = \\\n",
    "    pd.Series([len(IndexTable.Classification[i].Items) for i in range(0,len(IndexTable.IndexLetter))], index=IndexTable.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dyn_MFA_System = msc.MFAsystem(Name = 'PreliminaryApplianceSystem', \n",
    "                      Geogr_Scope = 'Norway', \n",
    "                      Unit = '1', \n",
    "                      ProcessList = [], \n",
    "                      FlowDict = {}, \n",
    "                      StockDict = {},\n",
    "                      ParameterDict = {}, \n",
    "                      Time_Start = int(min(ModelClassification_app['Time'].Items)), \n",
    "                      Time_End = int(max(ModelClassification_app['Time'].Items)), \n",
    "                      IndexTable = IndexTable, \n",
    "                      Elements = IndexTable.loc['Element'].Classification.Items) # Initialize MFA system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dyn_MFA_System.ProcessList = [] # Start with empty process list, only process numbers (IDs) and names are needed.\n",
    "Dyn_MFA_System.ProcessList.append(msc.Process(Name = 'Environment', ID   = 0))\n",
    "Dyn_MFA_System.ProcessList.append(msc.Process(Name = 'Process 1'  , ID   = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dyn_MFA_System.ParameterDict = {\n",
    "    'I': msc.Parameter(Name = 'Inflow', Indices = 'td', Values=None, Unit = '1/yr'),\n",
    "    'P': msc.Parameter(Name = 'Population', Indices = 't', Values=None, Unit = 'people/yr'),\n",
    "    'PpD': msc.Parameter(Name = 'Person per dwelling', Indices = 't', Values=None, Unit = 'people/(dwelling*yr)'),\n",
    "    'C': msc.Parameter(Name = 'Cabins', Indices = 't', Values=None, Unit = 'cabins/yr'),\n",
    "    'k': msc.Parameter(Name = 'Durable lifetime (shape)', Indices = 'd', Values=None, Unit = '1'),\n",
    "    'lambda-cab': msc.Parameter(Name = 'Cabin lifetime (scale)', Indices = '', Values=None, Unit = '1'),\n",
    "    'k-cab': msc.Parameter(Name = 'Cabin lifetime (shape)', Indices = '', Values=None, Unit = '1'),\n",
    "    'SoCE': msc.Parameter(Name = 'Share of cabins electrified', Indices = 't', Values=None, Unit = '%')}\n",
    "\n",
    "excel = os.path.abspath(os.path.join(os.getcwd(), 'data.xlsx'))\n",
    "for k in Dyn_MFA_System.ParameterDict.keys():\n",
    "    indices = Dyn_MFA_System.ParameterDict[k].Indices\n",
    "    Dyn_MFA_System.ParameterDict[k].Values = funct.read_parameter_excel(IndexTable, indices, excel, sheet_name=k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = {'names': [], 'bounds': [], 'dists': []}\n",
    "for var in variables_for_UA:\n",
    "    uncert = globals()['u_'+var.lower().replace('-','_')]\n",
    "    variables['names'].append(var)\n",
    "    variables['bounds'].append([0,uncert])\n",
    "    variables['dists'].append('norm')\n",
    "\n",
    "problem = {\n",
    "        'num_vars': len(variables['names']),\n",
    "        'names': variables['names'], \n",
    "        'bounds': variables['bounds'], \n",
    "        'dists': variables['dists']\n",
    "        }\n",
    "# for normal 'norm' distribution, bounds indicate mean and st.dev\n",
    "\n",
    "# sample\n",
    "param_values = SALib.sample.sobol.sample(problem, SampleSize)\n",
    "no_of_runs = np.shape(param_values)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ModelClassification_app['Run'].Items = list(range(no_of_runs))\n",
    "IndexTable.Classification['Run'].Items = list(range(no_of_runs))\n",
    "IndexTable.IndexSize.loc['Run'] = no_of_runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the four flows a,b,c,d of the system, and initialise their values:\n",
    "Dyn_MFA_System.FlowDict['F_01'] = msc.Flow(Name = 'Input', P_Start = 0, P_End = 1, Indices = 't,d,r,e', Values=None)\n",
    "Dyn_MFA_System.FlowDict['F_10c'] = msc.Flow(Name = 'Output', P_Start = 1, P_End = 0, Indices = 't,c,d,r,e', Values=None)\n",
    "Dyn_MFA_System.StockDict['S_1c'] = msc.Stock(Name='In-use stock', P_Res=1, Type=0, Indices='t,c,d,r,e', Values=None)\n",
    "Dyn_MFA_System.StockDict['dS_1'] = msc.Stock(Name='In-use stock change', P_Res=1, Type=1, Indices='t,d,r,e',Values=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dyn_MFA_System.ExtraDict = {}\n",
    "Dyn_MFA_System.ExtraDict['S_1'] = msc.Parameter(Name = 'In-use stock total', Indices = 'tdr', Values=None)\n",
    "Dyn_MFA_System.ExtraDict['F_10'] = msc.Parameter(Name = 'Outflows total', Indices = 'tdr', Values=None)\n",
    "Dyn_MFA_System.ExtraDict['POpD'] = msc.Parameter(Name = 'Product ownership per dwelling', Indices = 'tdr', Values=None) \n",
    "Dyn_MFA_System.ExtraDict['hz'] = msc.Parameter(Name = 'Hazard matrix', Indices = 'tcdr', Values=None)\n",
    "Dyn_MFA_System.ExtraDict['LT-l'] = msc.Parameter(Name = 'Durable lifetime (scale)', Indices = 'tdr', Values=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in Dyn_MFA_System.ExtraDict.keys():\n",
    "    Dyn_MFA_System.ExtraDict[key].Values = np.zeros(tuple([len(IndexTable.set_index('IndexLetter').loc[x]['Classification'].Items) for x in Dyn_MFA_System.ExtraDict[key].Indices]))\n",
    "Dyn_MFA_System.Initialize_FlowValues()\n",
    "Dyn_MFA_System.Initialize_StockValues() \n",
    "Dyn_MFA_System.Consistency_Check()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_popd = funct.read_data_excel(IndexTable, 'td',excel, sheet_name='POpD_data')\n",
    "start_regression = time.time()\n",
    "for d,durable in enumerate(ModelClassification_app['Durable'].Items):\n",
    "    start_regression_d = time.time()\n",
    "    print(f\"Fitting lifetime for {durable}...\")\n",
    "    dict_values = funct.reduce_dimensions(IndexTable, durable, Dyn_MFA_System.ParameterDict)\n",
    "    df_d = df_popd[df_popd['durable'] == durable]\n",
    "    xdata = df_d['time'].values\n",
    "    ydata = df_d['value'].values\n",
    "    for r in range(no_of_runs):\n",
    "        dict_values_r = funct.multiply_by_uncertainty(durable, problem, param_values[r,:], dict_values,Dyn_MFA_System.ParameterDict)\n",
    "        dict_values_r['t'] = MyYears\n",
    "        lt_par0 = [20] \n",
    "        bounds = ([0],[40])\n",
    "        lt_fit_result = least_squares(errfunc_var, lt_par0, bounds=bounds, args=(xdata, ydata, dict_values_r))\n",
    "        \n",
    "        Dyn_MFA_System = save_MFA_results(Dyn_MFA_System, dict_values_r, d, r, lt_fit_result.x)\n",
    "        if r % 100 == 0 and r != 0:\n",
    "            print(f'iteration {r} in {no_of_runs}')\n",
    "        \n",
    "    end_regression_d = time.time()\n",
    "    print(f'Time elapsed for {durable}: {math.trunc((end_regression_d-start_regression_d)/60)} min {round((end_regression_d-start_regression_d) % 60)} s')\n",
    "end_regression = time.time()\n",
    "print(f'Time elapsed total: {math.trunc((end_regression-start_regression)/60)} min {round((end_regression-start_regression) % 60)} s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate mean lifetime\n",
    "mu = np.zeros([len(ModelClassification_app['Time'].Items), len(ModelClassification_app['Durable'].Items)+1, len(ModelClassification_app['Run'].Items)])\n",
    "for d,durable in enumerate(ModelClassification_app['Durable'].Items):\n",
    "    dict_values = funct.reduce_dimensions(IndexTable, durable, Dyn_MFA_System.ParameterDict)\n",
    "    for r in range(no_of_runs):\n",
    "        dict_values_r = funct.multiply_by_uncertainty(durable, problem, param_values[r,:], dict_values,Dyn_MFA_System.ParameterDict)\n",
    "        scale = Dyn_MFA_System.ExtraDict['LT-l'].Values[:,d,r]\n",
    "        mu[:,d,r] = funct.mean_from_scale_parameters(scale, dict_values_r)\n",
    "Dyn_MFA_System.ExtraDict['mu'] = msc.Parameter(Name = 'Durable lifetime (mean)', Indices = 'tdr', Values=mu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate age\n",
    "age_o_i = np.empty((len(MyYears), len(ModelClassification_app['Durable'].Items), no_of_runs))\n",
    "age_o = np.empty((len(MyYears), len(ModelClassification_app['Durable'].Items), no_of_runs))\n",
    "for d, durable in enumerate(ModelClassification_app['Durable'].Items):\n",
    "    for r in range(no_of_runs):\n",
    "        o_c = Dyn_MFA_System.FlowDict['F_10c'].Values[:,:,d,r,0]\n",
    "        age_o_i[:,d,r] = funct.calculate_age(o_c,isstock=False,inflows=Dyn_MFA_System.FlowDict['F_01'].Values[:,d,r,0])\n",
    "        age_o[:,d,r] = funct.calculate_age(o_c,isstock=False)\n",
    "Dyn_MFA_System.ExtraDict['age_o_i'] = msc.Parameter(Name = 'Mean age of outflows, scaled by inflows', Indices = 'tdr', Values=age_o_i)\n",
    "Dyn_MFA_System.ExtraDict['age_o'] = msc.Parameter(Name = 'Mean age of outflows', Indices = 'tdr', Values=age_o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"2_preliminary_analysis_global.dat\", \"wb\") as f:\n",
    "     pickle.dump([Dyn_MFA_System, problem, param_values, no_of_runs], f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = IndexTable.Classification['Time'].Items\n",
    "columns = 2\n",
    "rows = 4\n",
    "fig = plt.figure(figsize=(6*columns, 3.5*rows), constrained_layout=True)\n",
    "# fig.set_dpi(dpi) #min 600 for publication\n",
    "gs = fig.add_gridspec(rows, columns,hspace=0.1)\n",
    "row = 0\n",
    "col = 0\n",
    "for d,durable in enumerate(ModelClassification_app['Durable'].Items):\n",
    "    ax = fig.add_subplot(gs[row, col])\n",
    "    for r in range(no_of_runs):\n",
    "        ax.plot(MyYears, mu[:,d,r], color='C0', alpha=0.2)\n",
    "    ax.set_xlabel('Year')\n",
    "    ax.set_ylabel('Mean lifetime (years)')\n",
    "    ax.set_title(durable.capitalize())\n",
    "    ax.set_ylim(8, 37)\n",
    "    if col == columns-1:\n",
    "        col = 0\n",
    "        row+= 1\n",
    "    else:\n",
    "        col += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = IndexTable.Classification['Time'].Items\n",
    "columns = 2\n",
    "rows = 4\n",
    "fig = plt.figure(figsize=(6*columns, 3.5*rows), constrained_layout=True)\n",
    "# fig.set_dpi(dpi) #min 600 for publication\n",
    "gs = fig.add_gridspec(rows, columns,hspace=0.1)\n",
    "row = 0\n",
    "col = 0\n",
    "df_popd = funct.read_data_excel(IndexTable, 'td',excel, sheet_name='POpD_data')\n",
    "for d,durable in enumerate(ModelClassification_app['Durable'].Items):\n",
    "    df_d = df_popd[df_popd['durable'] == durable]\n",
    "    ax = fig.add_subplot(gs[row, col])\n",
    "    for r in range(no_of_runs):\n",
    "        popd_model = Dyn_MFA_System.ExtraDict['POpD'].Values[:,d,r]\n",
    "        ax.plot(MyYears, popd_model, color='C0', alpha=0.1, zorder=r)\n",
    "    ax.set_xlabel('Year')\n",
    "    ax.set_ylabel('Product ownership per dwelling')\n",
    "    ax.set_title(durable.capitalize())\n",
    "    ax.scatter(df_d['time'].values,df_d['value'].values, color='black', zorder=r+1)\n",
    "    if col == columns-1:\n",
    "        col = 0\n",
    "        row+= 1\n",
    "    else:\n",
    "        col += 1\n",
    "plt.xlim(1940-4,2022+4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sobol_St = {}\n",
    "sobol_S1 = {}\n",
    "sobol_St_CI = {}\n",
    "sobol_S1_CI = {}\n",
    "for d,durable in enumerate(IndexTable.Classification['Durable'].Items):\n",
    "    problem_d = problem\n",
    "    sobol_indices = [SALib.analyze.sobol.analyze(problem, Y) for Y in Dyn_MFA_System.ExtraDict['LT-l'].Values[:,d,:no_of_runs]]\n",
    "    sobol_St[durable] = np.array([s['ST'] for s in sobol_indices])\n",
    "    sobol_S1[durable] = np.array([s['S1'] for s in sobol_indices])\n",
    "    sobol_St_CI[durable] = np.array([s['ST_conf'] for s in sobol_indices])\n",
    "    sobol_S1_CI[durable] = np.array([s['S1_conf'] for s in sobol_indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = sobol_St[durable]\n",
    "\n",
    "data = {}\n",
    "for i in range(0,len(problem[\"names\"])):\n",
    "    name = problem[\"names\"][i]\n",
    "    values = S[:, i][20:] # fix here!!! it only shows years \n",
    "    data[name] = values\n",
    "df = pd.DataFrame(data)\n",
    "df.index = IndexTable.Classification['Time'].Items[20:]\n",
    "df.index.names = ['Year']\n",
    "\n",
    "labels = problem[\"names\"]\n",
    "labels.reverse()\n",
    "plt.stackplot(df.index,\n",
    "            [df[i] for i in labels],\n",
    "            labels=labels, colors=sns.color_palette(\"Spectral\", len(problem[\"names\"])))\n",
    "\n",
    "plt.legend(reversed(plt.legend().legendHandles), reversed(labels), loc=2, fontsize='large', bbox_to_anchor=(1, 1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sobol_St_scaled = {durable: sobol_St[durable][-1, :]/np.sum(sobol_St[durable][-1, :]) for durable in ModelClassification_app['Durable'].Items}\n",
    "\n",
    "durables = ModelClassification_app['Durable'].Items\n",
    "weight_counts = {name: np.array([sobol_St_scaled[durable][i] for durable in ModelClassification_app['Durable'].Items]) for i,name in enumerate(problem['names'])}\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "bottom = np.zeros(len(durables))\n",
    "for name, weight_count in weight_counts.items():\n",
    "    p = ax.bar(durables, weight_count, 0.5, label=name, bottom=bottom)\n",
    "    bottom += weight_count\n",
    "\n",
    "# ax.set_title(\"Number of penguins with above average body mass\")\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "plt.xticks(rotation=90)\n",
    "ax.legend(handles[::-1], labels[::-1], loc=\"upper left\", bbox_to_anchor=(1, 1))\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "odym",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
