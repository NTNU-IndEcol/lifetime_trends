{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 4 - results plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Jupyter notebook contains parts of modeling behind the publication: \n",
    "> Krych, K. & Pettersen, JB. (2024). Long-term lifetime trends of large appliances since the introduction in Norwegian households. Journal of Industrial Ecology. \n",
    "\n",
    "Here, we combine the results from the other Jupyter Notebooks in order to summarize and plot them. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and simulation setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import scipy.stats\n",
    "import SALib.analyze.sobol\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), os.pardir, 'odym/odym/modules')))\n",
    "import ODYM_Classes as msc # import the ODYM class file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "durables = ['fridges' ,'freezers','washing machines', 'tumble dryers', 'dishwashers', 'ovens']\n",
    "TimeStart = 1940\n",
    "TimeEnd = 2022\n",
    "MyYears = list(range(TimeStart,TimeEnd+1))\n",
    "excel = os.path.abspath(os.path.join(os.getcwd(), 'data.xlsx'))\n",
    "export_data_to_xlsx = True\n",
    "export_figs_to_pdf = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_i_data = pd.read_excel(excel, sheet_name='I_data')\n",
    "df_i_ip = pd.read_excel(excel, sheet_name='I')\n",
    "df_popd = pd.read_excel(excel, sheet_name='POpD_data')\n",
    "df_lt = pd.read_excel(excel, sheet_name='LT_data')\n",
    "unique_i = list(df_i_data[\"data type\"].unique())\n",
    "unique_popd = list(df_popd[\"unit\"].unique())\n",
    "palette_data_types = dict(zip(unique_i+unique_popd, sns.color_palette(\"colorblind\", n_colors=len(unique_i+unique_popd))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"3a_analysis_constant.dat\", \"rb\") as f:\n",
    "    [Dyn_MFA_System1, problem1, param_values1, no_of_runs1] = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"3b_analysis_variable.dat\", \"rb\") as f:\n",
    "    [Dyn_MFA_System2, problem2, param_values2, no_of_runs2] = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"2_preliminary_analysis_global.dat\", \"rb\") as f:\n",
    "    [Dyn_MFA_System3, problem3, param_values3, no_of_runs3] = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_array_with_nans(array, indices, no_of_runs):\n",
    "    max_no_of_runs = max(no_of_runs.values())\n",
    "    index_d = indices.index('d')\n",
    "    index_r = indices.index('r')\n",
    "    for d,durable in enumerate(durables):\n",
    "        index = [slice(None)]*len(indices)\n",
    "        index[index_d] = d\n",
    "        index[index_r] = np.r_[no_of_runs[durable]:max_no_of_runs]\n",
    "        array[tuple(index)] = np.nan\n",
    "    return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mean_and_percentiles(array,index_r):\n",
    "    avg = np.nanmean(array, axis=index_r).flatten(order='F')\n",
    "    perc_0th = np.nanpercentile(array, 0, axis=index_r).flatten(order='F')\n",
    "    perc_5th = np.nanpercentile(array, 5, axis=index_r).flatten(order='F')\n",
    "    perc_25th = np.nanpercentile(array, 25, axis=index_r).flatten(order='F')\n",
    "    perc_50th = np.nanpercentile(array, 50, axis=index_r).flatten(order='F')\n",
    "    perc_75th = np.nanpercentile(array, 75, axis=index_r).flatten(order='F')\n",
    "    perc_95th = np.nanpercentile(array, 95, axis=index_r).flatten(order='F')\n",
    "    perc_100th = np.nanpercentile(array, 100, axis=index_r).flatten(order='F')\n",
    "    data = np.concatenate(([avg],[perc_0th],[perc_5th],[perc_25th],[perc_50th],[perc_75th],[perc_95th],[perc_100th]), axis=0)\n",
    "    col_names = ['average', '0th percentile', '5th percentile', '25th percentile', '50th percentile', '75th percentile', '95th percentile', '100th percentile']\n",
    "    return data, col_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main manuscript"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 1 - inflows & ownership"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_xlim(df_popd_d, df_i_d, uncertainty=True, u=0.05):\n",
    "    popd_mean = df_popd_d[df_popd_d['time'].isin(range(1985,1996))]['value'].mean()\n",
    "    popd_max = df_popd_d['value'].max()\n",
    "    i_mean = df_i_d[df_i_d['time'].isin(range(1985,1996))]['value'].mean()\n",
    "    if uncertainty:\n",
    "        i_max = df_i_d['value'].max()*1.02*(1+u*1.96)\n",
    "    else:\n",
    "        i_max = df_i_d['value'].max()*1.05\n",
    "    popd_share = popd_mean/popd_max\n",
    "    i_share = i_mean/i_max\n",
    "    if i_share<popd_share:\n",
    "        i_ylim = i_max\n",
    "        popd_ylim = popd_max*popd_share/i_share\n",
    "    else:\n",
    "        i_ylim = i_max*i_share/popd_share\n",
    "        popd_ylim = popd_max\n",
    "    return i_ylim, popd_ylim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = 2\n",
    "rows = 3\n",
    "fig = plt.figure(figsize=(5*columns, 3*rows), constrained_layout=True)\n",
    "fig.set_dpi(800) #min 600 for publication\n",
    "gs = fig.add_gridspec(rows, columns,hspace=0.1,wspace=0.05)\n",
    "row = 0\n",
    "col = 0\n",
    "u = 0.05\n",
    "for d,durable in enumerate(durables):\n",
    "    if durable == durables[0]:\n",
    "        labels = ['(right axis) Ownership, data', '(left axis) Sales/year, data', '(left axis) Sales/year, averaged and interpolated', '(left axis) Sales/year, assumed 95% uncertainty interval']\n",
    "    else:\n",
    "        labels = ['_nolegend_']*4\n",
    "    df_popd_d = df_popd[(df_popd['durable'] == durable) | (df_popd['durable'] == durable+' [excluded]')]\n",
    "    df_i_d = df_i_data[df_i_data['durable'] == durable]\n",
    "    df_i_ip_d = df_i_ip[df_i_ip['durable'] == durable]\n",
    "    i_ylim, popd_ylim = calculate_xlim(df_popd_d, df_i_d)\n",
    "    df_popd_d = df_popd_d[df_popd_d['source'] != 'assumption']\n",
    "    ax1 = fig.add_subplot(gs[row, col])\n",
    "    ax2 = ax1.twinx()\n",
    "    # sns.scatterplot(data=df_popd_d, x='time', y='value', hue='data type', s=50, palette=palette_data_types, ax=ax1)\n",
    "    sns.scatterplot(data=df_i_d, x='time', y='value', s=30, ax=ax1, marker=\"o\", color='C2', alpha=0.8, label=labels[1])\n",
    "    sns.scatterplot(data=df_popd_d, x='time', y='value', s=20, ax=ax2, marker=\"D\", color=\".2\", alpha=1, label=labels[0])\n",
    "    sns.lineplot(data=df_i_ip_d, x='time', y='value', ax=ax1, color='C2', alpha=0.8, label=labels[2])\n",
    "    ax1.fill_between(MyYears, df_i_ip_d['value']*(1-u*1.96), df_i_ip_d['value']*(1+u*1.96), color='gray', alpha=0.5, label=labels[3],zorder=0)\n",
    "    # ax2.axhline(y=0.25,color=\"grey\", linestyle=\"--\")\n",
    "    ax2.axhline(y=0.5,color=\"grey\", linestyle=\"--\", alpha=0.5)\n",
    "    # ax2.axhline(y=0.75,color=\"grey\", linestyle=\"--\")\n",
    "    ax2.axhline(y=1,color=\"grey\", linestyle=\"--\", alpha=0.5)\n",
    "    \"\"\"if durable in ['fridges', 'washing machines', 'ovens']:\n",
    "        ax1.axvline(x=1960,color=\"grey\", linestyle=\"--\", alpha=0.5)\n",
    "    ax1.axvline(x=1970,color=\"grey\", linestyle=\"--\", alpha=0.5)\n",
    "    ax1.axvline(x=1980,color=\"grey\", linestyle=\"--\", alpha=0.5)\n",
    "    ax1.axvline(x=1990,color=\"grey\", linestyle=\"--\", alpha=0.5)\n",
    "    ax1.axvline(x=2000,color=\"grey\", linestyle=\"--\", alpha=0.5)\n",
    "    ax1.axvline(x=2010,color=\"grey\", linestyle=\"--\", alpha=0.5)\"\"\"\n",
    "    ax1.legend('')\n",
    "    ax2.legend('')\n",
    "    ax1.get_legend().remove()\n",
    "    ax2.get_legend().remove()\n",
    "    ax1.set_xlabel('Year')\n",
    "    ax1.set_ylabel('Sales/year')\n",
    "    ax2.set_ylabel('Ownership')\n",
    "    ax1.set_xlim(TimeStart-4, TimeEnd+4)\n",
    "    ax1.set_ylim(0,i_ylim)\n",
    "    ax2.set_ylim(0,popd_ylim)\n",
    "    ax1.set_title(durable.capitalize())\n",
    "    if col == columns-1:\n",
    "        col = 0\n",
    "        row+= 1\n",
    "    else:\n",
    "        col += 1\n",
    "lines_labels = [ax.get_legend_handles_labels() for ax in fig.axes]\n",
    "lines, labels = [sum(lol, []) for lol in zip(*lines_labels)]\n",
    "fig.legend(lines, labels, bbox_to_anchor=(0.5,0), loc=\"upper center\", fontsize=12)\n",
    "plt.show()\n",
    "if export_figs_to_pdf:\n",
    "    fig.savefig('outputs/Fig1.pdf', format='pdf', bbox_inches = \"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 2 - ownership model vs data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Dyn_MFA_System1.IndexTable.Classification['Time'].Items\n",
    "columns = 2\n",
    "rows = 3\n",
    "fig = plt.figure(figsize=(6*columns, 3.5*rows), constrained_layout=True)\n",
    "fig.set_dpi(800) #min 600 for publication\n",
    "gs = fig.add_gridspec(rows, columns,hspace=0.1)\n",
    "row = 0\n",
    "col = 0\n",
    "for d,durable in enumerate(Dyn_MFA_System1.IndexTable['Classification']['Durable'].Items):\n",
    "    df_popd_d = df_popd[df_popd['durable'] == durable]\n",
    "    df_popd_d_excluded = df_popd[df_popd['durable'] == durable+' [excluded]']\n",
    "    ax = fig.add_subplot(gs[row, col])\n",
    "    for r in range(no_of_runs1[durable]):\n",
    "        if durable == durables[0] and r == 0:\n",
    "            labels = ['Constant lifetime model results']\n",
    "        else:\n",
    "            labels = ['_nolegend_']\n",
    "        ax.plot(x, Dyn_MFA_System1.ExtraDict['POpD'].Values[:,d,r], color='C0', alpha=0.05, label=labels[0])\n",
    "    for r in range(no_of_runs2[durable]):\n",
    "        if durable == durables[0] and r == 0:\n",
    "            labels = ['Variable lifetime model results']\n",
    "        else:\n",
    "            labels = ['_nolegend_']\n",
    "        ax.plot(x, Dyn_MFA_System2.ExtraDict['POpD'].Values[:,d,r], color='C1', alpha=0.05, label=labels[0])\n",
    "    if durable == durables[0]:\n",
    "        labels = ['Data', 'Assumption']\n",
    "    else:\n",
    "        labels = ['_nolegend_']*2\n",
    "    sns.scatterplot(data=df_popd_d[df_popd_d['source'] != 'assumption'], x='time', y='value', s=40, marker=\"D\", color=\"black\", label=labels[0],zorder=r+1)\n",
    "    sns.scatterplot(data=df_popd_d[df_popd_d['source'] == 'assumption'], x='time', y='value', s=40, marker=\"D\", color=\"gray\", label=labels[1],zorder=r+1)\n",
    "    sns.scatterplot(data=df_popd_d_excluded, x='time', y='value', s=40, marker=\"D\", color=\"red\", label='Excluded data',zorder=r+1)\n",
    "    ax.set_xlabel('Year')\n",
    "    ax.set_ylabel('Ownership')\n",
    "    ax.set_title(durable.capitalize())\n",
    "    ax.set_xlim(1940-4,2022+4)\n",
    "    ax.legend('')\n",
    "    ax.get_legend().remove()\n",
    "    if col == columns-1:\n",
    "        col = 0\n",
    "        row+= 1\n",
    "    else:\n",
    "        col += 1\n",
    "lines_labels = [ax.get_legend_handles_labels() for ax in fig.axes]\n",
    "lines, labels = [sum(lol, []) for lol in zip(*lines_labels)]\n",
    "leg = fig.legend(lines, labels, bbox_to_anchor=(0.5,0), loc=\"upper center\", fontsize=12)\n",
    "for l in leg.get_lines(): # full answer: https://stackoverflow.com/questions/35200094/change-size-alpha-of-markers-in-the-legend-box\n",
    "    l.set_alpha(1)\n",
    "    # l.set_linewidth(5)\n",
    "plt.show()\n",
    "if export_figs_to_pdf:\n",
    "    fig.savefig('outputs/Fig2.pdf', format='pdf', bbox_inches = \"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if export_data_to_xlsx:\n",
    "    parameter = Dyn_MFA_System1.ExtraDict['POpD']\n",
    "    array = get_array_with_nans(parameter.Values, parameter.Indices, no_of_runs1)\n",
    "    data, col_names = calculate_mean_and_percentiles(array,parameter.Indices.index('r'))\n",
    "    df = pd.DataFrame(data=data.T, index=pd.MultiIndex.from_product([durables, MyYears], names=['durable','time']), columns=col_names)\n",
    "    df.to_excel('outputs/Fig2_constant.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if export_data_to_xlsx:\n",
    "    parameter = Dyn_MFA_System2.ExtraDict['POpD']\n",
    "    array = get_array_with_nans(parameter.Values, parameter.Indices, no_of_runs2)\n",
    "    data, col_names = calculate_mean_and_percentiles(array,parameter.Indices.index('r'))\n",
    "    df = pd.DataFrame(data=data.T, index=pd.MultiIndex.from_product([durables, MyYears], names=['durable','time']), columns=col_names)\n",
    "    df.to_excel('outputs/Fig2_variable.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 3 - outflows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_w = pd.read_excel(excel, sheet_name='W')\n",
    "df_w['durable'] = df_w['durable'].astype(\"category\")\n",
    "df_w['durable'] = df_w['durable'].cat.set_categories(durables)\n",
    "df_w = df_w.sort_values(by=['durable'])\n",
    "weight = list(df_w['value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_groups = {'cooling appliances': ['fridges', 'freezers'],\n",
    "            'other big appliances': ['washing machines', 'tumble dryers', 'dishwashers', 'ovens']}\n",
    "outflows_constant = np.zeros((len(MyYears),2,min(no_of_runs1.values())))\n",
    "outflows_logistic = np.zeros((len(MyYears),2,min(no_of_runs2.values())))\n",
    "for g, cat in enumerate(app_groups.keys()):\n",
    "    durables_cat = [item for item in app_groups[cat] if item in durables]\n",
    "    d_cat= [Dyn_MFA_System1.IndexTable['Classification']['Durable'].Items.index(durable) for durable in durables_cat]\n",
    "    weight_cat = [weight[d] for d in d_cat]\n",
    "    for r in range(min(no_of_runs1.values())):\n",
    "        y = 0\n",
    "        for i, d in enumerate(d_cat):\n",
    "            weight_d = weight_cat[i]\n",
    "            y += Dyn_MFA_System1.ExtraDict['F_10'].Values[:,d,r]*weight_d/1000\n",
    "        outflows_constant[:,g,r] = y\n",
    "    for r in range(min(no_of_runs2.values())):\n",
    "        y = 0\n",
    "        for i, d in enumerate(d_cat):\n",
    "            weight_d = weight_cat[i]\n",
    "            y += Dyn_MFA_System2.ExtraDict['F_10'].Values[:,d,r]*weight_d/1000\n",
    "        outflows_logistic[:,g,r] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_o = pd.read_excel(excel, sheet_name='O_data')\n",
    "x = Dyn_MFA_System1.IndexTable['Classification']['Time'].Items\n",
    "fig = plt.figure(figsize=(10, 3), constrained_layout=True)\n",
    "gs = fig.add_gridspec(1, 2,wspace=0.05)\n",
    "row = 0\n",
    "col = 0\n",
    "for g,cat in enumerate(app_groups.keys()):\n",
    "    ax = fig.add_subplot(gs[row, col])\n",
    "    df_o_d = df_o[df_o['durable category'] == cat]\n",
    "    y_val = df_o_d['value']\n",
    "    x_val = df_o_d['time']\n",
    "    fig.set_dpi(800) #min 600 for publication\n",
    "    for r in range(min(no_of_runs1.values())):\n",
    "        if r == 0 and cat == 'cooling appliances':\n",
    "            labels = ['Constant lifetime model results']\n",
    "        else:\n",
    "            labels = ['_nolegend_']\n",
    "        sns.lineplot(ax=ax, x=MyYears,y=outflows_constant[:,g,r], color='C0', alpha=0.05, label=labels[0],legend=False)\n",
    "    for r in range(min(no_of_runs2.values())):\n",
    "        if r == 0 and cat == 'cooling appliances':\n",
    "            labels = ['Variable lifetime model results']\n",
    "        else:\n",
    "            labels = ['_nolegend_']\n",
    "        sns.lineplot(ax=ax, x=MyYears,y=outflows_logistic[:,g,r], color='C1', alpha=0.05, label=labels[0],legend=False)\n",
    "    if  cat == 'cooling appliances':\n",
    "        labels = ['Data']\n",
    "    else:\n",
    "        labels = ['_nolegend_']\n",
    "    sns.scatterplot(ax=ax, x=x_val, y=y_val, label=labels[0],zorder=r+1, color='black',legend=False)\n",
    "    ax.set_ylabel(f'Outflows (tons)')\n",
    "    ax.set_xlabel('Year')\n",
    "    ax.set_title(cat.capitalize())\n",
    "    col += 1\n",
    "lines_labels = [ax.get_legend_handles_labels() for ax in fig.axes]\n",
    "lines, labels = [sum(lol, []) for lol in zip(*lines_labels)]\n",
    "leg = fig.legend(lines, labels, bbox_to_anchor=(0.5,0), loc=\"upper center\", fontsize=12)\n",
    "for l in leg.get_lines(): # full answer: https://stackoverflow.com/questions/35200094/change-size-alpha-of-markers-in-the-legend-box\n",
    "    l.set_alpha(1)\n",
    "plt.show()\n",
    "if export_figs_to_pdf:\n",
    "    fig.savefig('outputs/Fig3.pdf', format='pdf', bbox_inches = \"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if export_data_to_xlsx:\n",
    "    data, col_names = calculate_mean_and_percentiles(outflows_constant,2)\n",
    "    df = pd.DataFrame(data=data.T, index=pd.MultiIndex.from_product([app_groups.keys(), MyYears], names=['category','time']), columns=col_names)\n",
    "    df.to_excel('outputs/Fig3_constant.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if export_data_to_xlsx:\n",
    "    data, col_names = calculate_mean_and_percentiles(outflows_logistic,2)\n",
    "    df = pd.DataFrame(data=data.T, index=pd.MultiIndex.from_product([app_groups.keys(), MyYears], names=['category','time']), columns=col_names)\n",
    "    df.to_excel('outputs/Fig3_variable.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 4 - lifetimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Dyn_MFA_System1.IndexTable.Classification['Time'].Items\n",
    "columns = 2\n",
    "rows = 3\n",
    "fig = plt.figure(figsize=(6*columns, 3.5*rows))\n",
    "fig.set_dpi(800) #min 600 for publication\n",
    "gs = fig.add_gridspec(rows, columns*9,hspace=0.4,wspace=0.1)\n",
    "row = 0\n",
    "col = 0\n",
    "for d,durable in enumerate(Dyn_MFA_System1.IndexTable['Classification']['Durable'].Items):\n",
    "    ax = fig.add_subplot(gs[row, col*9])\n",
    "    sns.kdeplot(y=Dyn_MFA_System1.ExtraDict['mu'].Values[0,d,:no_of_runs1[durable]], color='C0', bw_adjust=1.5, alpha=1)\n",
    "    sns.kdeplot(y=Dyn_MFA_System2.ExtraDict['mu'].Values[0,d,:no_of_runs2[durable]], color='C1', bw_adjust=1.5, alpha=1)\n",
    "    ax.set_ylim(0, 38)\n",
    "    ax.set_ylabel('Mean lifetime (years)')\n",
    "    ax.invert_xaxis()\n",
    "    ax.set_xlabel('')\n",
    "    # ax.set_xlim(0, 1.1)\n",
    "    ax.set_xticks([],labels=None)\n",
    "    ax.axhline(y=10,color=\"grey\", linestyle=\"--\", alpha=0.5)\n",
    "    ax.axhline(y=20,color=\"grey\", linestyle=\"--\", alpha=0.5)\n",
    "    ax.axhline(y=30,color=\"grey\", linestyle=\"--\", alpha=0.5)\n",
    "\n",
    "    ax = fig.add_subplot(gs[row, col*9+7])\n",
    "    sns.kdeplot(y=Dyn_MFA_System1.ExtraDict['mu'].Values[-1,d,:no_of_runs1[durable]], color='C0', bw_adjust=1.5, alpha=1)\n",
    "    sns.kdeplot(y=Dyn_MFA_System2.ExtraDict['mu'].Values[-1,d,:no_of_runs2[durable]], color='C1', bw_adjust=1.5, alpha=1)\n",
    "    ax.set_ylim(0, 38)\n",
    "    ax.set_ylabel('')\n",
    "    ax.set_yticks([],labels=None)\n",
    "    ax.set_xlabel('')\n",
    "    # ax.set_xlim(0, 1.1)\n",
    "    ax.set_xticks([],labels=None)\n",
    "    ax.axhline(y=10,color=\"grey\", linestyle=\"--\", alpha=0.5)\n",
    "    ax.axhline(y=20,color=\"grey\", linestyle=\"--\", alpha=0.5)\n",
    "    ax.axhline(y=30,color=\"grey\", linestyle=\"--\", alpha=0.5)\n",
    "\n",
    "    ax = fig.add_subplot(gs[row, col*9+1:col*9+7])\n",
    "    ax.axhline(y=10,color=\"grey\", linestyle=\"--\", alpha=0.5)\n",
    "    ax.axhline(y=20,color=\"grey\", linestyle=\"--\", alpha=0.5)\n",
    "    ax.axhline(y=30,color=\"grey\", linestyle=\"--\", alpha=0.5)\n",
    "    if durable == durables[0]:\n",
    "        labels = ['Literature data']\n",
    "    else:\n",
    "        labels = ['_nolegend_']\n",
    "    df_lt_d = df_lt[df_lt['durable'] == durable]\n",
    "    sns.scatterplot(data=df_lt_d, x='reference year', y='mean', label=labels[0],color='black',zorder=no_of_runs2[durable], legend=False)\n",
    "    for r in range(no_of_runs2[durable]):\n",
    "        if durable == durables[0] and r == 0:\n",
    "            labels = ['Variable lifetime model results']\n",
    "        else:\n",
    "            labels = ['_nolegend_']\n",
    "        ax.plot(x, Dyn_MFA_System2.ExtraDict['mu'].Values[:,d,r], color='C1', alpha=0.1, label=labels[0])\n",
    "    for r in range(no_of_runs1[durable]):\n",
    "        if durable == durables[0] and r == 0:\n",
    "            labels = ['Constant lifetime model results']\n",
    "        else:\n",
    "            labels = ['_nolegend_']\n",
    "        ax.plot(x, Dyn_MFA_System1.ExtraDict['mu'].Values[:,d,r], color='C0', alpha=0.1, label=labels[0])\n",
    "    ax.set_xlabel('Year')\n",
    "    ax.set_ylabel('')\n",
    "    ax.set_yticks([],labels=None)\n",
    "    ax.set_title(durable.capitalize())\n",
    "    ax.set_ylim(0, 38)\n",
    "    ax.set_xlim(TimeStart, TimeEnd)\n",
    "    if col == columns-1:\n",
    "        col = 0\n",
    "        row+= 1\n",
    "    else:\n",
    "        col += 1\n",
    "lines_labels = [ax.get_legend_handles_labels() for ax in fig.axes]\n",
    "lines, labels = [sum(lol, []) for lol in zip(*lines_labels)]\n",
    "leg = fig.legend(reversed(lines), reversed(labels), bbox_to_anchor=(0.5,0.07), loc=\"upper center\", fontsize=12)\n",
    "for l in leg.get_lines(): # full answer: https://stackoverflow.com/questions/35200094/change-size-alpha-of-markers-in-the-legend-box\n",
    "    l.set_alpha(1)\n",
    "    # l.set_linewidth(5)\n",
    "plt.show()\n",
    "if export_figs_to_pdf:\n",
    "    fig.savefig('outputs/Fig4.pdf', format='pdf', bbox_inches = \"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if export_data_to_xlsx:\n",
    "    parameter = Dyn_MFA_System1.ExtraDict['mu']\n",
    "    array = get_array_with_nans(parameter.Values, parameter.Indices, no_of_runs1)[0,:-1,:]\n",
    "    data, col_names = calculate_mean_and_percentiles(array,1)\n",
    "    df_fig4constant = pd.DataFrame(data=data.T, index=pd.MultiIndex.from_product([durables], names=['durable']), columns=col_names)\n",
    "    df_fig4constant.to_excel('outputs/Fig4_constant.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if export_data_to_xlsx:\n",
    "    parameter = Dyn_MFA_System2.ExtraDict['mu']\n",
    "    array = get_array_with_nans(parameter.Values, parameter.Indices, no_of_runs2)[:,:-1,:]\n",
    "    data, col_names = calculate_mean_and_percentiles(array,2)\n",
    "    df_fig4variable = pd.DataFrame(data=data.T, index=pd.MultiIndex.from_product([durables, MyYears], names=['durable','time']), columns=col_names)\n",
    "    df_fig4variable.to_excel('outputs/Fig4_variable.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculations for the manuscript"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### median and IQR values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for durable in ['fridges', 'dishwashers']:\n",
    "    d = Dyn_MFA_System1.IndexTable['Classification']['Durable'].Items.index(durable)\n",
    "    print(f\"{durable}, constant lifetime median {round(df_fig4constant['50th percentile'].loc[durable,],1)} with IQR of {round(df_fig4constant['25th percentile'].loc[durable,],1)} to {round(df_fig4constant['75th percentile'].loc[durable,],1)}\")\n",
    "for durable in ['fridges', 'dishwashers']:\n",
    "    d = Dyn_MFA_System1.IndexTable['Classification']['Durable'].Items.index(durable)\n",
    "    print(f\"{durable}, variable lifetime start: median {round(df_fig4variable['50th percentile'].loc[durable,1940],1)} with IQR of {round(df_fig4variable['25th percentile'].loc[durable,1940],1)} to {round(df_fig4variable['75th percentile'].loc[durable,1940],1)}\")\n",
    "    print(f\"{durable}, variable lifetime start: median {round(df_fig4variable['50th percentile'].loc[durable,2022],1)} with IQR of {round(df_fig4variable['25th percentile'].loc[durable,2022],1)} to {round(df_fig4variable['75th percentile'].loc[durable,2022],1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### overlap of 5-95th percentile intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_overlap(durable, year, lower='5th percentile', upper='95th percentile'):\n",
    "    x1 = df_fig4constant[lower].loc[durable,]\n",
    "    x2 = df_fig4constant[upper].loc[durable,]\n",
    "    y1 = df_fig4variable[lower].loc[durable,year]\n",
    "    y2 = df_fig4variable[upper].loc[durable,year]\n",
    "    return max(0,min(x2,y2)-max(x1,y1))\n",
    "\n",
    "df = pd.DataFrame(columns=['1940','2022','1940 (%)','2022 (%)'], index=durables)\n",
    "for durable in durables:\n",
    "    df['1940'].loc[durable] = calculate_overlap(durable, 1940)\n",
    "    df['2022'].loc[durable] = calculate_overlap(durable, 2022)\n",
    "    df['1940 (%)'].loc[durable] = calculate_overlap(durable, 1940)/(df_fig4constant['95th percentile'].loc[durable,]-df_fig4constant['5th percentile'].loc[durable,])\n",
    "    df['2022 (%)'].loc[durable] = calculate_overlap(durable, 2022)/(df_fig4constant['95th percentile'].loc[durable,]-df_fig4constant['5th percentile'].loc[durable,])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### median lifetime decrease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for durable in ['washing machines', 'ovens']:\n",
    "    d = Dyn_MFA_System1.IndexTable['Classification']['Durable'].Items.index(durable)\n",
    "    val1 = df_fig4variable['50th percentile'].loc[durable,1940]\n",
    "    val2 = df_fig4variable['50th percentile'].loc[durable,2022]\n",
    "    print(f'{durable}, lifetime decrease from median {round(val1,1)} to {round(val2,1)} ({round(((val2-val1)/val1)*100)}%)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### inflection point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for durable in ['washing machines', 'ovens']:\n",
    "    d = Dyn_MFA_System1.IndexTable['Classification']['Durable'].Items.index(durable)\n",
    "    no_of_runs = no_of_runs2[durable]\n",
    "    perc_5th = np.nanpercentile(Dyn_MFA_System2.ExtraDict['LT-l-ti'].Values[0,d,:no_of_runs], 5)\n",
    "    perc_95th = np.nanpercentile(Dyn_MFA_System2.ExtraDict['LT-l-ti'].Values[0,d,:no_of_runs], 95)\n",
    "    print(f'{durable}, inflection point: 5th percentile {round(perc_5th)}, 95th percentile {round(perc_95th)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SI figures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inflows of appliances - various sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = 2\n",
    "rows = 3\n",
    "fig = plt.figure(figsize=(5*columns, 3*rows), constrained_layout=True)\n",
    "# fig.set_dpi(dpi) #min 600 for publication\n",
    "gs = fig.add_gridspec(rows, columns,hspace=0.1,wspace=0.05)\n",
    "row = 0\n",
    "col = 0\n",
    "unique = df_i_data[\"source\"].unique()\n",
    "palette = dict(zip(unique, sns.color_palette(\"colorblind\", n_colors=len(unique))))\n",
    "markers = dict(zip(unique, ['o', 'v', '^', 's','P', 'X', 'D']))\n",
    "for d,durable in enumerate(durables):\n",
    "    df_i_d = df_i_data[df_i_data['durable'] == durable]\n",
    "    ax1 = fig.add_subplot(gs[row, col])\n",
    "    sns.scatterplot(ax=ax1, data=df_i_d, x='time', y='value', hue='source', style='source', hue_order= list(df_i_d['source'].unique()), markers=markers, palette=palette)\n",
    "    ax1.legend('')\n",
    "    ax1.get_legend().remove()\n",
    "    ax1.set_xlabel('Year')\n",
    "    ax1.set_ylabel('Sales/year')\n",
    "    ax1.set_xlim(TimeStart-4, TimeEnd+4)\n",
    "    ax1.set_title(durable.capitalize())\n",
    "    if col == columns-1:\n",
    "        col = 0\n",
    "        row+= 1\n",
    "    else:\n",
    "        col += 1\n",
    "lines_labels = [ax.get_legend_handles_labels() for ax in fig.axes]\n",
    "lines, labels = [sum(lol, []) for lol in zip(*lines_labels)]\n",
    "handle_list, label_list = [], []\n",
    "for handle, label in zip(lines, labels):\n",
    "    if label not in label_list:\n",
    "        handle_list.append(handle)\n",
    "        label_list.append(label)\n",
    "fig.legend(handle_list, label_list, bbox_to_anchor=(0.5,0), loc=\"upper center\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "markers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(df_i_d['source'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### POpD - various sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = 2\n",
    "rows = 3\n",
    "fig = plt.figure(figsize=(5*columns, 3*rows), constrained_layout=True)\n",
    "# fig.set_dpi(dpi) #min 600 for publication\n",
    "gs = fig.add_gridspec(rows, columns,hspace=0.1,wspace=0.05)\n",
    "row = 0\n",
    "col = 0\n",
    "unique = df_popd[\"source\"].unique()\n",
    "markers = dict(zip(unique, ['o', 'v', '^', 's','P', 'D']))\n",
    "palette = dict(zip(unique, sns.color_palette(\"colorblind\", n_colors=len(unique))))\n",
    "for d,durable in enumerate(durables):\n",
    "    df_popd_d = df_popd[df_popd['durable'] == durable]\n",
    "    df_popd_d = df_popd_d[df_popd_d['source'] != 'assumption']\n",
    "    ax1 = fig.add_subplot(gs[row, col])\n",
    "    sns.scatterplot(ax=ax1, data=df_popd_d, x='time', y='value', hue='source', style='source', hue_order= list(df_popd_d['source'].unique()), markers=markers, palette=palette)\n",
    "    ax1.axhline(y=0.5,color=\"grey\", linestyle=\"--\", alpha=0.5)\n",
    "    ax1.axhline(y=1,color=\"grey\", linestyle=\"--\", alpha=0.5)\n",
    "    ax1.legend('')\n",
    "    ax1.get_legend().remove()\n",
    "    ax1.set_xlabel('Year')\n",
    "    ax1.set_ylabel('Ownership')\n",
    "    ax1.set_xlim(TimeStart-4, TimeEnd+4)\n",
    "    ax1.set_ylim(-0.05,max(df_popd_d['value'])*1.2)\n",
    "    ax1.set_title(durable.capitalize())\n",
    "    if col == columns-1:\n",
    "        col = 0\n",
    "        row+= 1\n",
    "    else:\n",
    "        col += 1\n",
    "lines_labels = [ax.get_legend_handles_labels() for ax in fig.axes]\n",
    "lines, labels = [sum(lol, []) for lol in zip(*lines_labels)]\n",
    "handle_list, label_list = [], []\n",
    "for handle, label in zip(lines, labels):\n",
    "    if label not in label_list:\n",
    "        handle_list.append(handle)\n",
    "        label_list.append(label)\n",
    "fig.legend(handle_list, label_list, bbox_to_anchor=(0.5,0), loc=\"upper center\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Other parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_lt_k = 0.05   \n",
    "u_p = 0.01     \n",
    "u_ppd = 0.01    \n",
    "u_lt_cab_l = 0.2 \n",
    "u_lt_cab_k = 0.2 \n",
    "u_soce = 0.2     \n",
    "u_c = 0.01   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = 2\n",
    "rows = 2\n",
    "fig = plt.figure(figsize=(5*columns, 3*rows), constrained_layout=True)\n",
    "# fig.set_dpi(dpi) #min 600 for publication\n",
    "gs = fig.add_gridspec(rows, columns,hspace=0.1,wspace=0.05)\n",
    "# population\n",
    "row=0\n",
    "col=0\n",
    "ax1 = fig.add_subplot(gs[row, col])\n",
    "df = pd.read_excel(excel, sheet_name='P')\n",
    "df_full = df\n",
    "u = u_p\n",
    "sns.scatterplot(ax=ax1,data=df, x='time', y='value', label='Data points', color='black', s=10,zorder=2)\n",
    "sns.lineplot(ax=ax1,data=df_full, x='time', y='value', label='Full time series', color='gray',zorder=1)\n",
    "ax1.fill_between(MyYears, df_full['value']*(1-u*1.96), df_full['value']*(1+u*1.96), color='gray', alpha=0.5, label='Uncertainty, ±1.96*StDev',zorder=0)\n",
    "ax1.set_ylim(0,max(df['value'])*1.1)\n",
    "ax1.set_xlim(TimeStart-4, TimeEnd+4)\n",
    "ax1.set_xlabel('Year')\n",
    "ax1.set_ylabel('Population')\n",
    "ax1.set_title('Population')\n",
    "ax1.legend('')\n",
    "ax1.get_legend().remove()\n",
    "# people per dwelling\n",
    "row=0\n",
    "col=1\n",
    "ax1 = fig.add_subplot(gs[row, col])\n",
    "df = pd.read_excel(excel, sheet_name='PpD_data')\n",
    "df_full = pd.read_excel(excel, sheet_name='PpD')\n",
    "u = u_ppd\n",
    "sns.scatterplot(ax=ax1,data=df, x='time', y='value', label='Data points', color='black', s=10, zorder=2)\n",
    "sns.lineplot(ax=ax1,data=df_full, x='time', y='value', label='Full time series', color='gray',zorder=1)\n",
    "ax1.fill_between(MyYears, df_full['value']*(1-u*1.96), df_full['value']*(1+u*1.96), color='gray', alpha=0.5, label='Uncertainty, ±1.96*StDev',zorder=0)\n",
    "ax1.set_ylim(0,max(df['value'])*1.1)\n",
    "ax1.set_xlim(TimeStart-4, TimeEnd+4)\n",
    "ax1.set_xlabel('Year')\n",
    "ax1.set_ylabel('People per dwelling')\n",
    "ax1.set_title('People per dwelling')\n",
    "ax1.legend('')\n",
    "ax1.get_legend().remove()\n",
    "# stock of cabins\n",
    "row=1\n",
    "col=0\n",
    "ax1 = fig.add_subplot(gs[row, col])\n",
    "df = pd.read_excel(excel, sheet_name='C_data')\n",
    "df_full = pd.read_excel(excel, sheet_name='C')\n",
    "df_full = df_full[df_full['time'] >= 1940]\n",
    "u = u_c\n",
    "sns.scatterplot(ax=ax1,data=df, x='time', y='value', label='Data points', color='black', s=10,zorder=2)\n",
    "sns.lineplot(ax=ax1,data=df_full, x='time', y='value', label='Full time series', color='gray',zorder=1)\n",
    "ax1.fill_between(MyYears, df_full['value']*(1-u*1.96), df_full['value']*(1+u*1.96), color='gray', alpha=0.5, label='Uncertainty, ±1.96*StDev',zorder=0)\n",
    "ax1.set_ylim(0,max(df['value'])*1.1)\n",
    "ax1.set_xlim(TimeStart-4, TimeEnd+4)\n",
    "ax1.set_xlabel('Year')\n",
    "ax1.set_ylabel('Stock of cabins')\n",
    "ax1.set_title('Stock of cabins')\n",
    "ax1.legend('')\n",
    "ax1.get_legend().remove()\n",
    "# share of cabins electrified\n",
    "row=1\n",
    "col=1\n",
    "ax1 = fig.add_subplot(gs[row, col])\n",
    "df = pd.read_excel(excel, sheet_name='SoCE_data')\n",
    "df = df[df['source'] != 'assumption']\n",
    "df_assumption = pd.read_excel(excel, sheet_name='SoCE_data')\n",
    "df_assumption = df_assumption[df_assumption['source'] == 'assumption']\n",
    "df_full = pd.read_excel(excel, sheet_name='SoCE')\n",
    "u = u_soce\n",
    "sns.scatterplot(ax=ax1,data=df, x='time', y='value', label='Data points', color='black', s=20,zorder=2)\n",
    "sns.scatterplot(ax=ax1,data=df_assumption, x='time', y='value', label='Assumption', color='gray',marker='D', s=20,zorder=2)\n",
    "sns.lineplot(ax=ax1,data=df_full, x='time', y='value', label='Full time series', color='gray',zorder=1)\n",
    "soce_max = df_full['value']*(1+u*1.96)\n",
    "soce_max[soce_max>1] = 1\n",
    "ax1.fill_between(MyYears, df_full['value']*(1-u*1.96), soce_max, color='gray', alpha=0.5, label='Uncertainty, ±1.96*StDev',zorder=0)\n",
    "ax1.set_ylim(-0.05,1.1)\n",
    "ax1.set_xlim(TimeStart-4, TimeEnd+4)\n",
    "ax1.set_xlabel('Year')\n",
    "ax1.set_ylabel('Share of cabins electrified')\n",
    "ax1.set_title('Share of cabins electrified')\n",
    "ax1.legend('')\n",
    "ax1.get_legend().remove()\n",
    "# legend\n",
    "lines_labels = [ax.get_legend_handles_labels() for ax in fig.axes]\n",
    "lines, labels = [sum(lol, []) for lol in zip(*lines_labels)]\n",
    "handle_list, label_list = [], []\n",
    "for handle, label in zip(lines, labels):\n",
    "    if label not in label_list:\n",
    "        handle_list.append(handle)\n",
    "        label_list.append(label)\n",
    "fig.legend(handle_list, label_list, bbox_to_anchor=(0.5,0), loc=\"upper center\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sensitivity analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sobol_St = {}\n",
    "sobol_S1 = {}\n",
    "sobol_St_CI = {}\n",
    "sobol_S1_CI = {}\n",
    "for d,durable in enumerate(Dyn_MFA_System3.IndexTable.Classification['Durable'].Items):\n",
    "    problem_d = problem3\n",
    "    sobol_indices = [SALib.analyze.sobol.analyze(problem3, Y) for Y in Dyn_MFA_System3.ExtraDict['LT-l'].Values[:,d,:no_of_runs3]]\n",
    "    sobol_St[durable] = np.array([s['ST'] for s in sobol_indices])\n",
    "    sobol_S1[durable] = np.array([s['S1'] for s in sobol_indices])\n",
    "    sobol_St_CI[durable] = np.array([s['ST_conf'] for s in sobol_indices])\n",
    "    sobol_S1_CI[durable] = np.array([s['S1_conf'] for s in sobol_indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sobol_St_scaled = {durable: sobol_St[durable][-1, :]/np.sum(sobol_St[durable][-1, :]) for durable in Dyn_MFA_System3.IndexTable.Classification['Durable'].Items}\n",
    "\n",
    "durables = Dyn_MFA_System3.IndexTable.Classification['Durable'].Items\n",
    "weight_counts = {name: np.array([sobol_St_scaled[durable][i] for durable in Dyn_MFA_System3.IndexTable.Classification['Durable'].Items]) for i,name in enumerate(problem3['names'])}\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "bottom = np.zeros(len(durables))\n",
    "for name, weight_count in weight_counts.items():\n",
    "    p = ax.bar(durables, weight_count, 0.5, label=name, bottom=bottom)\n",
    "    bottom += weight_count\n",
    "\n",
    "# ax.set_title(\"Number of penguins with above average body mass\")\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "plt.xticks(rotation=90)\n",
    "ax.legend(handles[::-1], labels[::-1], loc=\"upper left\", bbox_to_anchor=(1, 1))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if export_data_to_xlsx:\n",
    "    df = pd.DataFrame.from_dict(data=weight_counts, orient='index', columns=durables)\n",
    "    df.to_excel('outputs/FigS4.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of dwellings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ppd = pd.read_excel(excel, sheet_name='PpD')\n",
    "df_p = pd.read_excel(excel, sheet_name='P')\n",
    "df_c = pd.read_excel(excel, sheet_name='C')\n",
    "df_soce = pd.read_excel(excel, sheet_name='SoCE')\n",
    "df_k_cab = pd.read_excel(excel, sheet_name='k-cab')\n",
    "df_l_cab = pd.read_excel(excel, sheet_name='lambda-cab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dwellings = np.array(df_p['value']/df_ppd['value'])\n",
    "\n",
    "t = df_c['time']\n",
    "s = df_c['value']\n",
    "scale = df_l_cab['value'].values[0]\n",
    "shape = df_k_cab['value'].values[0]\n",
    "sf = np.zeros((len(t), len(t)))\n",
    "for m in range(0, len(t)):  # cohort index\n",
    "    sf[m::,m] = scipy.stats.weibull_min.sf(np.arange(0,len(t)-m), c=shape, loc = 0, scale=scale)\n",
    "\n",
    "# MFA calculations start (assuming sf[0] != 0 and no negative inflows)\n",
    "i = np.zeros(len(t))\n",
    "s_c = np.zeros((len(t), len(t)))\n",
    "i[0] = s[0] / sf[0, 0]\n",
    "s_c[:, 0] = i[0] * sf[:, 0]\n",
    "for m in range(1, len(t)):\n",
    "    i[m] = (s[m] - s_c[m, :].sum()) / sf[m,m]\n",
    "    s_c[m::, m] = i[m] * sf[m::, m]\n",
    "\n",
    "o_c = np.zeros_like(s_c)\n",
    "o_c[1::,:] = -1 * np.diff(s_c,n=1,axis=0)\n",
    "o_c[np.diag_indices(len(t))] = i - np.diag(s_c) # allow for outflow in year 0 already\n",
    "\n",
    "soce = df_soce['value'] # share of cabins electrified\n",
    "soce[soce >1] = 1\n",
    "soce[:1960-TimeStart] = 0 \n",
    "soce[soce <0] = 0\n",
    "el_cabins = np.einsum('tc,c->t',s_c[40:,40:],soce)\n",
    "all_dwellings = dwellings+el_cabins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(5, 3), constrained_layout=True)\n",
    "ax = fig.add_subplot()\n",
    "ax.fill_between(MyYears, np.zeros_like(dwellings), dwellings/10**6, color='gray', label='Primary dwellings', alpha=0.5)\n",
    "ax.fill_between(MyYears, dwellings/10**6, all_dwellings/10**6, color='gray', label='Recreational cabins',alpha=1)\n",
    "a = (all_dwellings[-1] - all_dwellings[0])/(MyYears[-1] - MyYears[0])\n",
    "b = all_dwellings[0] - a*MyYears[0]\n",
    "ax.plot(MyYears, (a*np.array(MyYears)+b)/10**6)\n",
    "ax.set_ylabel('Dwelling stock (million)')\n",
    "ax.set_xlabel('Year')\n",
    "plt.legend(loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'all dwellings in 1940: {round(all_dwellings[0])} ({round(el_cabins[0]/all_dwellings[0]*100)}% cabins) and in  2022: {round(all_dwellings[-1])} ({round(el_cabins[-1]/all_dwellings[-1]*100)}% cabins)')\n",
    "perc_inc_p_y = np.concatenate([np.array([0]),np.diff(all_dwellings)])/all_dwellings\n",
    "print(f'the average increase per year in the total number of dwellings was {np.round(np.mean(perc_inc_p_y)*100,2)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if export_data_to_xlsx:\n",
    "    data = np.concatenate(([dwellings],[el_cabins]), axis=0)\n",
    "    df = pd.DataFrame(data=data.T, index=pd.MultiIndex.from_product([MyYears], names=['time']), columns=['primary dwellings', 'secondary dwellings'])\n",
    "    df.to_excel('outputs/FigS5.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Age of appliances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = 2\n",
    "rows = 3\n",
    "fig = plt.figure(figsize=(6*columns, 3.5*rows), constrained_layout=True)\n",
    "# fig.set_dpi(dpi) #min 600 for publication\n",
    "gs = fig.add_gridspec(rows, columns,hspace=0.1)\n",
    "row = 0\n",
    "col = 0\n",
    "for d,durable in enumerate(durables):\n",
    "    ax = fig.add_subplot(gs[row, col])\n",
    "    for r in range(no_of_runs1[durable]):\n",
    "        ax.plot(MyYears, Dyn_MFA_System1.ExtraDict['age_o'].Values[:,d,r], color='C0', alpha=0.1, label='Constant lifetime model results', zorder=r)\n",
    "        # ax.plot(MyYears, age_o[:,d,r], color='C1', alpha=0.1, zorder=r)\n",
    "    for r in range(no_of_runs2[durable]):\n",
    "        ax.plot(MyYears, Dyn_MFA_System2.ExtraDict['age_o'].Values[:,d,r], color='C1', alpha=0.1, label='Variable lifetime model results', zorder=r)\n",
    "    ax.set_xlabel('Year')\n",
    "    ax.set_ylabel('Age of outflows (years)')\n",
    "    ax.set_title(durable.capitalize())\n",
    "    # add validation data\n",
    "    df_lt_d = df_lt[df_lt['durable'] == durable]\n",
    "    xdata = df_lt_d['reference year'].values\n",
    "    ydata = df_lt_d['mean'].values\n",
    "    ax.scatter(xdata,ydata,color='black', label='Literature data',zorder=r+1)\n",
    "    ax.set_xlim(1940-4,2022+4)\n",
    "    ax.set_ylim(0,28)  \n",
    "    if col == columns-1:\n",
    "        col = 0\n",
    "        row+= 1\n",
    "    else:\n",
    "        col += 1\n",
    "lines_labels = [ax.get_legend_handles_labels() for ax in fig.axes]\n",
    "lines, labels = [sum(lol, []) for lol in zip(*lines_labels)]\n",
    "handle_list, label_list = [], []\n",
    "for handle, label in zip(lines, labels):\n",
    "    if label not in label_list:\n",
    "        handle_list.append(handle)\n",
    "        label_list.append(label)\n",
    "leg = fig.legend(handle_list, label_list, bbox_to_anchor=(0.5,0), loc=\"upper center\", fontsize=12)\n",
    "for l in leg.get_lines(): # full answer: https://stackoverflow.com/questions/35200094/change-size-alpha-of-markers-in-the-legend-box\n",
    "    l.set_alpha(1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if export_data_to_xlsx:\n",
    "    parameter = Dyn_MFA_System1.ExtraDict['age_o']\n",
    "    array = get_array_with_nans(parameter.Values, parameter.Indices, no_of_runs1)\n",
    "    data, col_names = calculate_mean_and_percentiles(array,2)\n",
    "    df = pd.DataFrame(data=data.T, index=pd.MultiIndex.from_product([durables, MyYears], names=['durable','time']), columns=col_names)\n",
    "    df.to_excel('outputs/FigS6_constant.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if export_data_to_xlsx:\n",
    "    parameter = Dyn_MFA_System2.ExtraDict['age_o']\n",
    "    array = get_array_with_nans(parameter.Values, parameter.Indices, no_of_runs2)\n",
    "    data, col_names = calculate_mean_and_percentiles(array,2)\n",
    "    df = pd.DataFrame(data=data.T, index=pd.MultiIndex.from_product([durables, MyYears], names=['durable','time']), columns=col_names)\n",
    "    df.to_excel('outputs/FigS6_variable.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = 2\n",
    "rows = 3\n",
    "fig = plt.figure(figsize=(6*columns, 3.5*rows), constrained_layout=True)\n",
    "# fig.set_dpi(dpi) #min 600 for publication\n",
    "gs = fig.add_gridspec(rows, columns,hspace=0.1)\n",
    "row = 0\n",
    "col = 0\n",
    "for d,durable in enumerate(durables):\n",
    "    ax = fig.add_subplot(gs[row, col])\n",
    "    for r in range(no_of_runs1[durable]):\n",
    "        ax.plot(MyYears, Dyn_MFA_System1.ExtraDict['age_o_i'].Values[:,d,r], color='C0', alpha=0.1, label='Constant lifetime model results', zorder=r)\n",
    "        # ax.plot(MyYears, age_o[:,d,r], color='C1', alpha=0.1, zorder=r)\n",
    "    for r in range(no_of_runs2[durable]):\n",
    "        ax.plot(MyYears, Dyn_MFA_System2.ExtraDict['age_o_i'].Values[:,d,r], color='C1', alpha=0.1, label='Variable lifetime model results', zorder=r)\n",
    "    ax.set_xlabel('Year')\n",
    "    ax.set_ylabel('Age of outflows (years)')\n",
    "    ax.set_title(durable.capitalize())\n",
    "    # add validation data\n",
    "    df_lt_d = df_lt[df_lt['durable'] == durable]\n",
    "    xdata = df_lt_d['reference year'].values\n",
    "    ydata = df_lt_d['mean'].values\n",
    "    ax.scatter(xdata,ydata,color='black', label='Literature data',zorder=r+1)\n",
    "    ax.set_xlim(1940-4,2022+4)\n",
    "    ax.set_ylim(0,28)  \n",
    "    if col == columns-1:\n",
    "        col = 0\n",
    "        row+= 1\n",
    "    else:\n",
    "        col += 1\n",
    "lines_labels = [ax.get_legend_handles_labels() for ax in fig.axes]\n",
    "lines, labels = [sum(lol, []) for lol in zip(*lines_labels)]\n",
    "handle_list, label_list = [], []\n",
    "for handle, label in zip(lines, labels):\n",
    "    if label not in label_list:\n",
    "        handle_list.append(handle)\n",
    "        label_list.append(label)\n",
    "leg = fig.legend(handle_list, label_list, bbox_to_anchor=(0.5,0), loc=\"upper center\", fontsize=12)\n",
    "for l in leg.get_lines(): # full answer: https://stackoverflow.com/questions/35200094/change-size-alpha-of-markers-in-the-legend-box\n",
    "    l.set_alpha(1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if export_data_to_xlsx:\n",
    "    parameter = Dyn_MFA_System1.ExtraDict['age_o_i']\n",
    "    array = get_array_with_nans(parameter.Values, parameter.Indices, no_of_runs1)\n",
    "    data, col_names = calculate_mean_and_percentiles(array,2)\n",
    "    df = pd.DataFrame(data=data.T, index=pd.MultiIndex.from_product([durables, MyYears], names=['durable','time']), columns=col_names)\n",
    "    df.to_excel('outputs/FigS7_constant.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if export_data_to_xlsx:\n",
    "    parameter = Dyn_MFA_System2.ExtraDict['age_o_i']\n",
    "    array = get_array_with_nans(parameter.Values, parameter.Indices, no_of_runs2)\n",
    "    data, col_names = calculate_mean_and_percentiles(array,2)\n",
    "    df = pd.DataFrame(data=data.T, index=pd.MultiIndex.from_product([durables, MyYears], names=['durable','time']), columns=col_names)\n",
    "    df.to_excel('outputs/FigS7_variable.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot and export the scale parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "mean = {k: np.zeros((len(durables))) for k in ['ti', 'a', 'C0', 'C1', 'constant']}\n",
    "mode = {k: np.zeros((len(durables))) for k in ['ti', 'a', 'C0', 'C1', 'constant']}\n",
    "median = {k: np.zeros((len(durables))) for k in ['ti', 'a', 'C0', 'C1', 'constant']}\n",
    "for d,durable in enumerate(durables):\n",
    "    mode['constant'][d] = stats.mode(np.round(Dyn_MFA_System1.ExtraDict['LT-l'].Values[0,d,:no_of_runs2[durable]],0)).mode\n",
    "    mode['ti'][d] = stats.mode(np.round(Dyn_MFA_System2.ExtraDict['LT-l-ti'].Values[0,d,:no_of_runs2[durable]],0)).mode\n",
    "    mode['a'][d] = stats.mode(np.round(Dyn_MFA_System2.ExtraDict['LT-l-a'].Values[0,d,:no_of_runs2[durable]],1)).mode\n",
    "    mode['C0'][d] = stats.mode(np.round(Dyn_MFA_System2.ExtraDict['LT-l-C0'].Values[0,d,:no_of_runs2[durable]],1)).mode\n",
    "    mode['C1'][d] = stats.mode(np.round(Dyn_MFA_System2.ExtraDict['LT-l-C1'].Values[0,d,:no_of_runs2[durable]],1)).mode\n",
    "    mean['constant'][d] = np.mean(Dyn_MFA_System1.ExtraDict['LT-l'].Values[0,d,:no_of_runs2[durable]])\n",
    "    mean['ti'][d] = np.mean(Dyn_MFA_System2.ExtraDict['LT-l-ti'].Values[0,d,:no_of_runs2[durable]])\n",
    "    mean['a'][d] = np.mean(Dyn_MFA_System2.ExtraDict['LT-l-a'].Values[0,d,:no_of_runs2[durable]])\n",
    "    mean['C0'][d] = np.mean(Dyn_MFA_System2.ExtraDict['LT-l-C0'].Values[0,d,:no_of_runs2[durable]])\n",
    "    mean['C1'][d] = np.mean(Dyn_MFA_System2.ExtraDict['LT-l-C1'].Values[0,d,:no_of_runs2[durable]])\n",
    "    median['constant'][d] = np.median(Dyn_MFA_System1.ExtraDict['LT-l'].Values[0,d,:no_of_runs2[durable]])\n",
    "    median['ti'][d] = np.median(Dyn_MFA_System2.ExtraDict['LT-l-ti'].Values[0,d,:no_of_runs2[durable]])\n",
    "    median['a'][d] = np.median(Dyn_MFA_System2.ExtraDict['LT-l-a'].Values[0,d,:no_of_runs2[durable]])\n",
    "    median['C0'][d] = np.median(Dyn_MFA_System2.ExtraDict['LT-l-C0'].Values[0,d,:no_of_runs2[durable]])\n",
    "    median['C1'][d] = np.median(Dyn_MFA_System2.ExtraDict['LT-l-C1'].Values[0,d,:no_of_runs2[durable]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic(x, ti, a, C0, C1):\n",
    "    return (C1 - C0) / (1 + np.exp(-a * (x - ti))) + C0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Dyn_MFA_System1.IndexTable.Classification['Time'].Items\n",
    "columns = 2\n",
    "rows = 3\n",
    "fig = plt.figure(figsize=(6*columns, 3.5*rows), constrained_layout=True)\n",
    "gs = fig.add_gridspec(rows, columns,hspace=0.1)\n",
    "row = 0\n",
    "col = 0\n",
    "for d,durable in enumerate(Dyn_MFA_System1.IndexTable['Classification']['Durable'].Items):\n",
    "    ax = fig.add_subplot(gs[row, col])\n",
    "    if durable == durables[0]:\n",
    "        labels = ['constant mean', 'constant mode', 'constant median', 'logistic mean','logistic mode', 'logistic median']\n",
    "    else:\n",
    "        labels = ['_nolegend_']*6\n",
    "    ax.plot(x, mean['constant'][d]*np.ones_like(x), label=labels[0], color='C0', linestyle='-')\n",
    "    ax.plot(x, mode['constant'][d]*np.ones_like(x), label=labels[1], color='C0', linestyle='--')\n",
    "    ax.plot(x, median['constant'][d]*np.ones_like(x), label=labels[2], color='C0', linestyle=':')\n",
    "    ax.plot(x, logistic(MyYears, mean['ti'][d], mean['a'][d], mean['C0'][d], mean['C1'][d]), label=labels[3], color='C1', linestyle='-')\n",
    "    ax.plot(x, logistic(MyYears, mode['ti'][d], mode['a'][d], mode['C0'][d], mode['C1'][d]), label=labels[4], color='C1', linestyle='--')\n",
    "    ax.plot(x, logistic(MyYears, median['ti'][d], median['a'][d], median['C0'][d], median['C1'][d]), label=labels[5], color='C1', linestyle=':')\n",
    "    ax.set_xlabel('Year')\n",
    "    ax.set_ylabel('Appliance ownership')\n",
    "    ax.set_title(durable.capitalize())\n",
    "    ax.set_xlim(1940-4,2022+4)\n",
    "    ax.set_ylim(0,30)\n",
    "    ax.legend('')\n",
    "    if col == columns-1:\n",
    "        col = 0\n",
    "        row+= 1\n",
    "    else:\n",
    "        col += 1\n",
    "lines_labels = [ax.get_legend_handles_labels() for ax in fig.axes]\n",
    "lines, labels = [sum(lol, []) for lol in zip(*lines_labels)]\n",
    "leg = fig.legend(lines, labels, bbox_to_anchor=(0.5,0), loc=\"upper center\", fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data=mean['constant'].flatten(order='F'), index=pd.MultiIndex.from_product([durables], names=['durable']), columns=['value'])\n",
    "df.to_excel('outputs/scale_mean_constant.xlsx')\n",
    "\n",
    "data = np.zeros((len(MyYears),len(durables)))\n",
    "for d, durable in enumerate(durables):\n",
    "    data[:,d] = logistic(MyYears, mean['ti'][d], mean['a'][d], mean['C0'][d], mean['C1'][d])\n",
    "df = pd.DataFrame(data=data.flatten(order='F'), index=pd.MultiIndex.from_product([durables,MyYears], names=['durable','time']), columns=['value'])\n",
    "df.to_excel('outputs/scale_mean_variable.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "odym",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "88a8cd6dab7e39e26651f15ad9527b438eba8983743c187474a3cdf275f3d522"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
