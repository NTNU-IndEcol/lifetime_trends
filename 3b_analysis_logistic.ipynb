{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 3b - final analysis, logistic lifetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Jupyter notebook contains parts of modeling behind the publication: \n",
    "> Krych, K. & Pettersen, JB. (2024). Long-term lifetime trends of large appliances since the introduction in Norwegian households. Journal of Industrial Ecology. \n",
    "\n",
    "Here, we perform the final analysis, where we keep all parameters fixed, except for \"inflows of appliances (I)\". We divide the inflows of appliances into approximately decade-long segments, which we vary independently. \n",
    "\n",
    "We assume that the lifetime scale parameter follows a *logistic* function.\n",
    "\n",
    "Please note: depending on the computational power of your machine, the code below might take 60+ minutes to execute."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and simulation setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats\n",
    "from scipy.optimize import least_squares\n",
    "import SALib.sample.sobol\n",
    "import time\n",
    "import math\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), os.pardir, 'ODYM/odym/modules')))\n",
    "import ODYM_Classes as msc # import the ODYM class file\n",
    "from timeseriessegments import TimeSeriesSegments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TimeStart = 1940\n",
    "TimeEnd = 2022\n",
    "SampleSize = 2**5\n",
    "\n",
    "problem = {}\n",
    "param_values = {}\n",
    "variables = {}\n",
    "MyYears = list(range(TimeStart,TimeEnd+1))\n",
    "variables_for_UA = ['I']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all values below are relative changes in parameters (percentage changes)\n",
    "u_i = 0.05\n",
    "u_k = 0.1   \n",
    "u_p = 0.01     \n",
    "u_ppd = 0.01    \n",
    "u_lambda_cab = 0.2 \n",
    "u_k_cab = 0.2 \n",
    "u_soce = 0.2     \n",
    "u_i_cab = 0.01 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import funct # most functions are imported from funct.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lt_par_to_scale(t, lt_par):\n",
    "    [ti, a, C0, C1] = lt_par\n",
    "    scale = (C1 - C0) / (1 + np.exp(-a * (t - ti))) + C0\n",
    "    return scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_MFA(lt_par, dict_values):\n",
    "    t = dict_values['t']\n",
    "    scale = lt_par_to_scale(t, lt_par)\n",
    "    # create a 2D array with shape parameters\n",
    "    lt_shape = np.full((len(t),len(t)), dict_values['k'], dtype=float)\n",
    "    lt_shape = np.tril(lt_shape, 0)\n",
    "    # create a 2D array with scale parameters\n",
    "    lt_scale = np.repeat(np.reshape(scale,(len(scale),1)), repeats=len(scale), axis=1)\n",
    "    lt_scale = np.tril(lt_scale, 0)\n",
    "    lt = {'Type': 'Weibull', 'Shape': lt_shape,'Scale': lt_scale}\n",
    "    # __find_unique_lt__\n",
    "    params = {k:v for k,v in lt.items() if k!= 'Type'}\n",
    "    sets = np.concatenate([[p] for p in params.values()], axis=0) # stacks all the p parameters\n",
    "    sets = sets.reshape(len(params),-1) # reshapes from 3D form (p,t,t) into 2D form (p,t*t)\n",
    "    unique, inverse = np.unique(sets, return_inverse=True, axis=1)\n",
    "    inverse = inverse.reshape(len(t),len(t)) # reshapes from 1D form (t*t) into 2D form (t,t)\n",
    "    length = np.shape(unique)[1]\n",
    "    unique = {k:unique[p,:] for p,k in enumerate(params.keys())}\n",
    "    # __compute_hz__\n",
    "    hz_unique = np.zeros((len(t),length))\n",
    "    for i in range(length): # for each unique parameter set\n",
    "        if unique['Scale'][i] != 0:\n",
    "            sf = scipy.stats.weibull_min.sf(np.arange(len(t)), c=unique['Shape'][i], loc = 0, scale=unique['Scale'][i])\n",
    "            hz_unique[0,i] = 1-sf[0]\n",
    "            for m in range(len(t)-1): # for each age m\n",
    "                if sf[m] != 0:\n",
    "                    hz_unique[m+1,i] = (sf[m] - sf[m+1]) / sf[m]\n",
    "                else:\n",
    "                    hz_unique[m+1,i] = 1\n",
    "    hz = np.zeros((len(t), len(t)))\n",
    "    for cohort in range(len(t)): # for each cohort c\n",
    "        for time in range(cohort,len(t)): # for each year t \n",
    "            hz[time,cohort] = hz_unique[time-cohort,inverse[time,cohort]]\n",
    "    # compute_inflow_driven_model\n",
    "    i = dict_values['I']\n",
    "    s_c = np.zeros((len(t), len(t))) # stock composition per year\n",
    "    o_c = np.zeros((len(t), len(t))) # outflow compositionO\n",
    "    for time in range(len(t)): # for each year t\n",
    "        if time>0: # the initial stock is assumed to be 0\n",
    "            o_c[time,:time] = s_c[time-1,:time] * hz[time,:time] \n",
    "            # subtract outflows of cohorts <m from the previous stock \n",
    "            s_c[time,:time] = s_c[time-1,:time] - o_c[time,:time]\n",
    "        # Add new cohort to stock\n",
    "        s_c[time,time] = i[time]\n",
    "        o_c[time,time] = s_c[time,time] * hz[time,time]\n",
    "    # popd calculation\n",
    "    popd = s_c.sum(axis=1)/dict_values['D']\n",
    "    return popd, i, o_c, s_c, hz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_MFA_results(Dyn_MFA_System, dict_values, d, r, lt_fit):\n",
    "    t = np.array(Dyn_MFA_System.IndexTable.Classification.Time.Items)\n",
    "    popd, i, o_c, s_c, hz = perform_MFA(lt_fit, dict_values)\n",
    "    Dyn_MFA_System.FlowDict['F_01'].Values[:,d,r,0] = i\n",
    "    Dyn_MFA_System.FlowDict['F_10c'].Values[:,:,d,r,0] = o_c\n",
    "    Dyn_MFA_System.ExtraDict['F_10'].Values[:,d,r] = np.sum(o_c, axis=1)\n",
    "    Dyn_MFA_System.StockDict['S_1c'].Values[:,:,d,r,0] = s_c\n",
    "    Dyn_MFA_System.ExtraDict['S_1'].Values[:,d,r] = np.sum(s_c, axis=1)\n",
    "    Dyn_MFA_System.ExtraDict['POpD'].Values[:,d,r]= popd\n",
    "    Dyn_MFA_System.ExtraDict['hz'].Values[:,:,d,r]= hz\n",
    "    Dyn_MFA_System.ExtraDict['LT-l-ti'].Values[:,d,r] = lt_fit[0]\n",
    "    Dyn_MFA_System.ExtraDict['LT-l-a'].Values[:,d,r] = lt_fit[1]\n",
    "    Dyn_MFA_System.ExtraDict['LT-l-C0'].Values[:,d,r] = lt_fit[2]\n",
    "    Dyn_MFA_System.ExtraDict['LT-l-C1'].Values[:,d,r] = lt_fit[3]\n",
    "    Dyn_MFA_System.ExtraDict['LT-l'].Values[:,d,r] = lt_par_to_scale(t, lt_fit)\n",
    "    return Dyn_MFA_System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def errfunc_var(lt_par, xdata, ydata, dict_values_r):\n",
    "    popd, i, o_c, s_c, hz = perform_MFA(lt_par, dict_values_r)\n",
    "    return popd[xdata-TimeStart]-ydata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ModelClassification_app  = {} # Create dictionary of model classifications\n",
    "\n",
    "ModelClassification_app['Time'] = msc.Classification(Name = 'Time', Dimension = 'Time', ID = 1, \n",
    "                                                 Items = MyYears)\n",
    "ModelClassification_app['Cohort'] = msc.Classification(Name = 'Cohort', Dimension = 'Time', ID = 2, \n",
    "                                                 Items = MyYears)\n",
    "ModelClassification_app['Element'] = msc.Classification(Name= 'Elements', Dimension = 'Element', ID = 3, \n",
    "                                                    Items = ['C'])\n",
    "ModelClassification_app['Durable'] = msc.Classification(Name = 'Durable', Dimension = 'Durable', ID = 4, \n",
    "                                                    Items = ['fridge & fridge freezer' ,'freezer','washing machine', 'tumble dryer', 'dishwasher', 'oven'])\n",
    "ModelClassification_app['Run'] = msc.Classification(Name = 'Model run', Dimension = 'Run', ID = 5, \n",
    "                                                    Items = [])\n",
    "aspects = ['Time','Element','Cohort', 'Durable', 'Run']\n",
    "letters = ['t','e', 'c','d', 'r']\n",
    "IndexTable = pd.DataFrame({'Aspect'        : aspects, # 'Time' and 'Element' must be present!\n",
    "                           'Description'   : ['Model aspect ' + asp for asp in aspects],\n",
    "                           'Dimension'     : [asp if asp != 'Cohort' else 'Time' for asp in aspects], # 'Time' and 'Element' are also dimensions\n",
    "                           'Classification': [ModelClassification_app[Aspect] for Aspect in aspects],\n",
    "                           'IndexLetter'   : letters}) # Unique one letter (upper or lower case) indices to be used later for calculations.\n",
    "IndexTable.set_index('Aspect', inplace = True) \n",
    "IndexTable['IndexSize'] = \\\n",
    "    pd.Series([len(IndexTable.Classification[i].Items) for i in range(0,len(IndexTable.IndexLetter))], index=IndexTable.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dyn_MFA_System = msc.MFAsystem(Name = 'ApplianceSystem_logisticLT', \n",
    "                      Geogr_Scope = 'Norway', \n",
    "                      Unit = '1', \n",
    "                      ProcessList = [], \n",
    "                      FlowDict = {}, \n",
    "                      StockDict = {},\n",
    "                      ParameterDict = {}, \n",
    "                      Time_Start = int(min(ModelClassification_app['Time'].Items)), \n",
    "                      Time_End = int(max(ModelClassification_app['Time'].Items)), \n",
    "                      IndexTable = IndexTable, \n",
    "                      Elements = IndexTable.loc['Element'].Classification.Items) # Initialize MFA system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dyn_MFA_System.ProcessList = [] # Start with empty process list, only process numbers (IDs) and names are needed.\n",
    "Dyn_MFA_System.ProcessList.append(msc.Process(Name = 'Environment', ID   = 0))\n",
    "Dyn_MFA_System.ProcessList.append(msc.Process(Name = 'Process 1'  , ID   = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dyn_MFA_System.ParameterDict = {\n",
    "    'I': msc.Parameter(Name = 'Inflow', Indices = 'td', Values=None, Unit = '1/yr'),\n",
    "    'k': msc.Parameter(Name = 'Durable lifetime (shape)', Indices = 'd', Values=None, Unit = '1'),\n",
    "    'D': msc.Parameter(Name = 'Number of dwellings (primary and secondary)', Indices = 't', Values=None, Unit = '1')}\n",
    "\n",
    "excel = os.path.abspath(os.path.join(os.getcwd(), 'data.xlsx'))\n",
    "for k in Dyn_MFA_System.ParameterDict.keys():\n",
    "    indices = Dyn_MFA_System.ParameterDict[k].Indices\n",
    "    Dyn_MFA_System.ParameterDict[k].Values = funct.read_parameter_excel(IndexTable, indices, excel, sheet_name=k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_seg = {}\n",
    "for d,durable in enumerate(ModelClassification_app['Durable'].Items):\n",
    "    y = Dyn_MFA_System.ParameterDict['I'].Values[:,d]\n",
    "    if durable in ['dishwasher', 'tumble dryer', 'freezer']:\n",
    "        segs = [1970,1980,1990,2000,2010]\n",
    "    else:\n",
    "        segs = [1960,1970,1980,1990,2000,2010]\n",
    "    i_seg[durable] =TimeSeriesSegments(x=list(MyYears),y=list(y), seg_delim=segs, y_name='I-seg')\n",
    "    i_seg[durable].add_uncertainties('norm',0,u_i)\n",
    "Dyn_MFA_System.ParameterDict['I'].MetaData = i_seg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_of_runs = {}\n",
    "for durable in ModelClassification_app['Durable'].Items:\n",
    "    variables[durable] = {}\n",
    "    if variables_for_UA == ['I']:\n",
    "        variables[durable] = {k: i_seg[durable].uncert[k] for k in ['names', 'bounds', 'dists']}\n",
    "    else:\n",
    "        variables_common = {'names': [], 'bounds': [], 'dists': []}\n",
    "        for var in variables_for_UA:\n",
    "            if var != 'I':\n",
    "                uncert = globals()['u_'+var.lower().replace('-','_')]\n",
    "                variables_common['names'].append(var)\n",
    "                variables_common['bounds'].append([0,uncert])\n",
    "                variables_common['dists'].append('norm')\n",
    "        for k,v in variables_common.items():\n",
    "            variables[durable][k] = v + i_seg[durable].uncert[k] #  + other_vars[k]\n",
    "    \n",
    "\n",
    "    problem[durable] = {\n",
    "            'num_vars': len(variables[durable]['names']),\n",
    "            'names': variables[durable]['names'], \n",
    "            'bounds': variables[durable]['bounds'], \n",
    "            'dists': variables[durable]['dists']\n",
    "            }\n",
    "    # for normal 'norm' distribution, bounds indicate mean and st.dev\n",
    "\n",
    "    # sample\n",
    "    param_values[durable] = SALib.sample.sobol.sample(problem[durable], SampleSize)\n",
    "    no_of_runs[durable] = np.shape(param_values[durable])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_no_of_runs = max([no_of_runs[d] for d in  ModelClassification_app['Durable'].Items])\n",
    "ModelClassification_app['Run'].Items = list(range(max_no_of_runs))\n",
    "IndexTable.Classification['Run'].Items = list(range(max_no_of_runs))\n",
    "IndexTable.IndexSize.loc['Run'] = max_no_of_runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the four flows a,b,c,d of the system, and initialise their values:\n",
    "Dyn_MFA_System.FlowDict['F_01'] = msc.Flow(Name = 'Input', P_Start = 0, P_End = 1, Indices = 't,d,r,e', Values=None)\n",
    "Dyn_MFA_System.FlowDict['F_10c'] = msc.Flow(Name = 'Output', P_Start = 1, P_End = 0, Indices = 't,c,d,r,e', Values=None)\n",
    "Dyn_MFA_System.StockDict['S_1c'] = msc.Stock(Name='In-use stock', P_Res=1, Type=0, Indices='t,c,d,r,e', Values=None)\n",
    "Dyn_MFA_System.StockDict['dS_1'] = msc.Stock(Name='In-use stock change', P_Res=1, Type=1, Indices='t,d,r,e',Values=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dyn_MFA_System.ExtraDict = {}\n",
    "Dyn_MFA_System.ExtraDict['S_1'] = msc.Parameter(Name = 'In-use stock total', Indices = 'tdr', Values=None)\n",
    "Dyn_MFA_System.ExtraDict['F_10'] = msc.Parameter(Name = 'Outflows total', Indices = 'tdr', Values=None)\n",
    "Dyn_MFA_System.ExtraDict['POpD'] = msc.Parameter(Name = 'Product ownership per dwelling', Indices = 'tdr', Values=None) # POpD could have indices 'tar' but 'tdr' makes the calculations easier\n",
    "Dyn_MFA_System.ExtraDict['hz'] = msc.Parameter(Name = 'Hazard matrix', Indices = 'tcdr', Values=None)\n",
    "Dyn_MFA_System.ExtraDict['LT-l'] = msc.Parameter(Name = 'Durable lifetime (scale)', Indices = 'tdr', Values=None)\n",
    "Dyn_MFA_System.ExtraDict['LT-l-C0'] = msc.Parameter(Name = 'Durable lifetime (scale); C0', Indices = 'tdr', Values=None)\n",
    "Dyn_MFA_System.ExtraDict['LT-l-C1'] = msc.Parameter(Name = 'Durable lifetime (scale); C1', Indices = 'tdr', Values=None)\n",
    "Dyn_MFA_System.ExtraDict['LT-l-a'] = msc.Parameter(Name = 'Durable lifetime (scale); a', Indices = 'tdr', Values=None)\n",
    "Dyn_MFA_System.ExtraDict['LT-l-ti'] = msc.Parameter(Name = 'Durable lifetime (scale); ti', Indices = 'tdr', Values=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in Dyn_MFA_System.ExtraDict.keys():\n",
    "    Dyn_MFA_System.ExtraDict[key].Values = np.zeros(tuple([len(IndexTable.set_index('IndexLetter').loc[x]['Classification'].Items) for x in Dyn_MFA_System.ExtraDict[key].Indices]))\n",
    "Dyn_MFA_System.Initialize_FlowValues()\n",
    "Dyn_MFA_System.Initialize_StockValues() \n",
    "Dyn_MFA_System.Consistency_Check()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_popd = funct.read_data_excel(IndexTable, 'td',excel, sheet_name='POpD_data')\n",
    "start_regression = time.time()\n",
    "for d,durable in enumerate(ModelClassification_app['Durable'].Items):\n",
    "    start_regression_d = time.time()\n",
    "    print(f\"Fitting lifetime for {durable}...\")\n",
    "    dict_values = funct.reduce_dimensions(IndexTable, durable, Dyn_MFA_System.ParameterDict)\n",
    "    df_d = df_popd[df_popd['durable'] == durable]\n",
    "    xdata = df_d['time'].values\n",
    "    ydata = df_d['value'].values\n",
    "    for r in range(no_of_runs[durable]):\n",
    "        dict_values_r = funct.multiply_by_uncertainty(durable, problem[durable], param_values[durable][r,:], dict_values,Dyn_MFA_System.ParameterDict)\n",
    "        dict_values_r['t'] = np.array(MyYears)\n",
    "\n",
    "        lt_par0 = [2000,  0.5, 20, 20] \n",
    "        bounds = ([1990, 0.25, 0, 0],[2010, 1, 40, 40])\n",
    "\n",
    "        lt_fit_result = least_squares(errfunc_var, lt_par0, bounds=bounds, args=(xdata, ydata, dict_values_r))\n",
    "        \n",
    "        Dyn_MFA_System = save_MFA_results(Dyn_MFA_System, dict_values_r, d, r, lt_fit_result.x)\n",
    "        if r % 100 == 0 and r != 0:\n",
    "            print(f'iteration {r} in {no_of_runs[durable]}')\n",
    "        \n",
    "    end_regression_d = time.time()\n",
    "    print(f'Time elapsed for {durable}: {math.trunc((end_regression_d-start_regression_d)/60)} min {round((end_regression_d-start_regression_d) % 60)} s')\n",
    "end_regression = time.time()\n",
    "print(f'Time elapsed total: {math.trunc((end_regression-start_regression)/60)} min {round((end_regression-start_regression) % 60)} s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = np.zeros([len(ModelClassification_app['Time'].Items), len(ModelClassification_app['Durable'].Items)+1, len(ModelClassification_app['Run'].Items)])\n",
    "for d,durable in enumerate(ModelClassification_app['Durable'].Items):\n",
    "    dict_values = funct.reduce_dimensions(IndexTable, durable, Dyn_MFA_System.ParameterDict)\n",
    "    for r in range(no_of_runs[durable]):\n",
    "        dict_values_r = funct.multiply_by_uncertainty(durable, problem[durable], param_values[durable][r,:], dict_values,Dyn_MFA_System.ParameterDict)\n",
    "        scale = Dyn_MFA_System.ExtraDict['LT-l'].Values[:,d,r]\n",
    "        mu[:,d,r] = funct.mean_from_scale_parameters(scale, dict_values_r)\n",
    "Dyn_MFA_System.ExtraDict['mu'] = msc.Parameter(Name = 'Durable lifetime (mean)', Indices = 'tdr', Values=mu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_o_i = np.empty((len(MyYears), len(ModelClassification_app['Durable'].Items), no_of_runs[durable]))\n",
    "age_o = np.empty((len(MyYears), len(ModelClassification_app['Durable'].Items), no_of_runs[durable]))\n",
    "for d, durable in enumerate(ModelClassification_app['Durable'].Items):\n",
    "    for r in range(no_of_runs[durable]):\n",
    "        o_c = Dyn_MFA_System.FlowDict['F_10c'].Values[:,:,d,r,0]\n",
    "        age_o_i[:,d,r] = funct.calculate_age(o_c,isstock=False,inflows=Dyn_MFA_System.FlowDict['F_01'].Values[:,d,r,0])\n",
    "        age_o[:,d,r] = funct.calculate_age(o_c,isstock=False)\n",
    "Dyn_MFA_System.ExtraDict['age_o_i'] = msc.Parameter(Name = 'Mean age of outflows, scaled by inflows', Indices = 'tdr', Values=age_o_i)\n",
    "Dyn_MFA_System.ExtraDict['age_o'] = msc.Parameter(Name = 'Mean age of outflows', Indices = 'tdr', Values=age_o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"3b_analysis_logistic.dat\", \"wb\") as f:\n",
    "    pickle.dump([Dyn_MFA_System, problem, param_values, no_of_runs], f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = IndexTable.Classification['Time'].Items\n",
    "columns = 2\n",
    "rows = 4\n",
    "fig = plt.figure(figsize=(6*columns, 3.5*rows), constrained_layout=True)\n",
    "# fig.set_dpi(dpi) #min 600 for publication\n",
    "gs = fig.add_gridspec(rows, columns,hspace=0.1)\n",
    "row = 0\n",
    "col = 0\n",
    "for d,durable in enumerate(ModelClassification_app['Durable'].Items):\n",
    "    ax = fig.add_subplot(gs[row, col])\n",
    "    for r in range(no_of_runs[durable]):\n",
    "        ax.plot(MyYears, mu[:,d,r], color='C0', alpha=0.2)\n",
    "    ax.set_xlabel('Year')\n",
    "    ax.set_ylabel('Mean lifetime (years)')\n",
    "    ax.set_title(durable.capitalize())\n",
    "    ax.set_ylim(0, 32)\n",
    "    if col == columns-1:\n",
    "        col = 0\n",
    "        row+= 1\n",
    "    else:\n",
    "        col += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = IndexTable.Classification['Time'].Items\n",
    "columns = 2\n",
    "rows = 4\n",
    "fig = plt.figure(figsize=(6*columns, 3.5*rows), constrained_layout=True)\n",
    "# fig.set_dpi(dpi) #min 600 for publication\n",
    "gs = fig.add_gridspec(rows, columns,hspace=0.1)\n",
    "row = 0\n",
    "col = 0\n",
    "df_popd = funct.read_data_excel(IndexTable, 'td',excel, sheet_name='POpD_data')\n",
    "for d,durable in enumerate(ModelClassification_app['Durable'].Items):\n",
    "    df_d = df_popd[df_popd['durable'] == durable]\n",
    "    ax = fig.add_subplot(gs[row, col])\n",
    "    for r in range(no_of_runs[durable]):\n",
    "        popd_model = Dyn_MFA_System.ExtraDict['POpD'].Values[:,d,r]\n",
    "        ax.plot(MyYears, popd_model, color='C0', alpha=0.1, zorder=r)\n",
    "    ax.set_xlabel('Year')\n",
    "    ax.set_ylabel('Product ownership per dwelling')\n",
    "    ax.set_title(durable.capitalize())\n",
    "    ax.scatter(df_d['time'].values,df_d['value'].values, color='black', zorder=r+1)\n",
    "    if col == columns-1:\n",
    "        col = 0\n",
    "        row+= 1\n",
    "    else:\n",
    "        col += 1\n",
    "plt.xlim(1940-4,2022+4)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "odym",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
